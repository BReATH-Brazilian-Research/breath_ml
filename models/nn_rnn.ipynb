{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN e RNN\n",
    "\n",
    "Nesse notebook, vamos treinar os modelos baseados em redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados\n",
    "\n",
    "Precisamos primeiramente preparar os dados.\n",
    "\n",
    "Vamos carregar os conjuntos de validação e treino, separar as features e o target, e normalizá-los."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar\n",
    "\n",
    "Carregamos os conjuntos separados anteriormente, junto com a descrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"..\\\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(dataset_folder+\"\\\\train_df\", 'rb')\n",
    "train_df = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(dataset_folder+\"\\\\val_df\", 'rb')\n",
    "val_df = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(dataset_folder+\"\\\\info.json\", 'r')\n",
    "info_dict = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nome_municipio',\n",
       " 'Dia',\n",
       " 'Precipitacao',\n",
       " 'Pressao_at_max',\n",
       " 'Pressao_at_min',\n",
       " 'Radiacao',\n",
       " 'Temp_max',\n",
       " 'Temp_min',\n",
       " 'Umidade',\n",
       " 'Max_vent',\n",
       " 'Velocidade_vent',\n",
       " 'Pop_estimada']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_names = info_dict[\"feature_names\"]\n",
    "\n",
    "features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação\n",
    "\n",
    "Verifica se existe algum problema com os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nome_municipio     0\n",
       "Dia                0\n",
       "Precipitacao       0\n",
       "Pressao_at_max     0\n",
       "Pressao_at_min     0\n",
       "Radiacao           0\n",
       "Temp_max           0\n",
       "Temp_min           0\n",
       "Umidade            0\n",
       "Max_vent           0\n",
       "Velocidade_vent    0\n",
       "Pop_estimada       0\n",
       "Casos              0\n",
       "Casos_pela_pop     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nome_municipio     0\n",
       "Dia                0\n",
       "Precipitacao       0\n",
       "Pressao_at_max     0\n",
       "Pressao_at_min     0\n",
       "Radiacao           0\n",
       "Temp_max           0\n",
       "Temp_min           0\n",
       "Umidade            0\n",
       "Max_vent           0\n",
       "Velocidade_vent    0\n",
       "Pop_estimada       0\n",
       "Casos              0\n",
       "Casos_pela_pop     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação\n",
    "\n",
    "Separamos os conjuntos de treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "train_features = train_df[features_names]\n",
    "val_features = val_df[features_names]\n",
    "\n",
    "drop_columns = [\"Nome_municipio\", \"Dia\"]\n",
    "\n",
    "for column in drop_columns:\n",
    "    train_features.drop(column, axis=\"columns\", inplace=True)\n",
    "    val_features.drop(column, axis=\"columns\", inplace=True)\n",
    "\n",
    "train_target = train_df[\"Casos_pela_pop\"]\n",
    "val_target = val_df[\"Casos_pela_pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_features.shape[1]\n",
    "n_target = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização\n",
    "\n",
    "Normalizamos os dados, e salvamos as distribuições para podermos normalizar posteriormente os outros conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos e salvamos as distribições das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = {}\n",
    "\n",
    "for column in train_features.columns:\n",
    "    train_dist[column] = {}\n",
    "    train_dist[column][\"mean\"] = description[column][\"mean\"]\n",
    "    train_dist[column][\"std\"] = description[column][\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train_dist.json\", \"w\")\n",
    "json.dump(train_dist, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "for df in [train_features, val_features]:\n",
    "    for column in train_features:\n",
    "        df.loc[:, column] = (df[column]-train_dist[column][\"mean\"])/train_dist[column][\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos se estão corretamente normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitacao</th>\n",
       "      <th>Pressao_at_max</th>\n",
       "      <th>Pressao_at_min</th>\n",
       "      <th>Radiacao</th>\n",
       "      <th>Temp_max</th>\n",
       "      <th>Temp_min</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Max_vent</th>\n",
       "      <th>Velocidade_vent</th>\n",
       "      <th>Pop_estimada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.245522e-16</td>\n",
       "      <td>-1.432445e-15</td>\n",
       "      <td>2.329507e-14</td>\n",
       "      <td>-1.473959e-15</td>\n",
       "      <td>-1.436714e-15</td>\n",
       "      <td>1.905683e-15</td>\n",
       "      <td>5.725955e-16</td>\n",
       "      <td>-1.154622e-16</td>\n",
       "      <td>-9.053457e-16</td>\n",
       "      <td>-1.784184e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>-3.754402e+00</td>\n",
       "      <td>-3.763698e+00</td>\n",
       "      <td>-2.740855e+00</td>\n",
       "      <td>-5.989725e+00</td>\n",
       "      <td>-6.060539e+00</td>\n",
       "      <td>-3.623111e+00</td>\n",
       "      <td>-2.937551e+00</td>\n",
       "      <td>-1.826297e+00</td>\n",
       "      <td>-3.112124e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>-7.682675e-01</td>\n",
       "      <td>-7.684687e-01</td>\n",
       "      <td>-6.173573e-01</td>\n",
       "      <td>-5.796011e-01</td>\n",
       "      <td>-5.648660e-01</td>\n",
       "      <td>-6.524339e-01</td>\n",
       "      <td>-6.598478e-01</td>\n",
       "      <td>-6.869443e-01</td>\n",
       "      <td>-2.882414e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>2.465197e-02</td>\n",
       "      <td>2.413291e-02</td>\n",
       "      <td>1.036241e-01</td>\n",
       "      <td>1.490688e-01</td>\n",
       "      <td>1.825455e-01</td>\n",
       "      <td>6.375657e-02</td>\n",
       "      <td>-7.367400e-02</td>\n",
       "      <td>-1.347116e-01</td>\n",
       "      <td>-2.394346e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.515670e-01</td>\n",
       "      <td>9.055588e-01</td>\n",
       "      <td>9.042712e-01</td>\n",
       "      <td>7.030119e-01</td>\n",
       "      <td>6.980666e-01</td>\n",
       "      <td>7.321128e-01</td>\n",
       "      <td>7.206848e-01</td>\n",
       "      <td>5.459954e-01</td>\n",
       "      <td>5.740864e-01</td>\n",
       "      <td>-1.117164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.892274e+01</td>\n",
       "      <td>2.317003e+00</td>\n",
       "      <td>2.323264e+00</td>\n",
       "      <td>7.149043e+00</td>\n",
       "      <td>3.233438e+00</td>\n",
       "      <td>4.557101e+00</td>\n",
       "      <td>2.277895e+00</td>\n",
       "      <td>2.342352e+01</td>\n",
       "      <td>1.335032e+01</td>\n",
       "      <td>1.216895e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitacao  Pressao_at_max  Pressao_at_min      Radiacao  \\\n",
       "count  1.784139e+06    1.784139e+06    1.784139e+06  1.784139e+06   \n",
       "mean  -2.245522e-16   -1.432445e-15    2.329507e-14 -1.473959e-15   \n",
       "std    1.000000e+00    1.000000e+00    1.000000e+00  1.000000e+00   \n",
       "min   -3.060475e-01   -3.754402e+00   -3.763698e+00 -2.740855e+00   \n",
       "25%   -3.060475e-01   -7.682675e-01   -7.684687e-01 -6.173573e-01   \n",
       "50%   -3.060475e-01    2.465197e-02    2.413291e-02  1.036241e-01   \n",
       "75%   -2.515670e-01    9.055588e-01    9.042712e-01  7.030119e-01   \n",
       "max    2.892274e+01    2.317003e+00    2.323264e+00  7.149043e+00   \n",
       "\n",
       "           Temp_max      Temp_min       Umidade      Max_vent  \\\n",
       "count  1.784139e+06  1.784139e+06  1.784139e+06  1.784139e+06   \n",
       "mean  -1.436714e-15  1.905683e-15  5.725955e-16 -1.154622e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.989725e+00 -6.060539e+00 -3.623111e+00 -2.937551e+00   \n",
       "25%   -5.796011e-01 -5.648660e-01 -6.524339e-01 -6.598478e-01   \n",
       "50%    1.490688e-01  1.825455e-01  6.375657e-02 -7.367400e-02   \n",
       "75%    6.980666e-01  7.321128e-01  7.206848e-01  5.459954e-01   \n",
       "max    3.233438e+00  4.557101e+00  2.277895e+00  2.342352e+01   \n",
       "\n",
       "       Velocidade_vent  Pop_estimada  \n",
       "count     1.784139e+06  1.784139e+06  \n",
       "mean     -9.053457e-16 -1.784184e-18  \n",
       "std       1.000000e+00  1.000000e+00  \n",
       "min      -1.826297e+00 -3.112124e-01  \n",
       "25%      -6.869443e-01 -2.882414e-01  \n",
       "50%      -1.347116e-01 -2.394346e-01  \n",
       "75%       5.740864e-01 -1.117164e-01  \n",
       "max       1.335032e+01  1.216895e+01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos o mesmo processo com o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = {}\n",
    "target_dist[\"mean\"] = train_target.mean()\n",
    "target_dist[\"std\"] = train_target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"target_dist.json\", \"w\")\n",
    "json.dump(target_dist, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: Só descobrimos posteriormente que a normalização do target não é realizada corretamente nessa célula. Portanto, em todos os momentos, o target utilizado é o target não normalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_target, val_target]:\n",
    "    df = (df-target_dist[\"mean\"])/target_dist[\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infraestrutura para treino\n",
    "\n",
    "Aqui, preparamos a estrutura básica para gerenciar os modelos que serão treinados.\n",
    "\n",
    "Para o logging das métricas e pesos, decidimos utilizar a ferramenta \"Weights and Biases\". Os loggings obtidos estão públicos nos nossos projetos:\n",
    "\n",
    "Parte do projeto | Link\n",
    "-|-\n",
    "Modelos treinados com dados diários | https://wandb.ai/breath/BReATH-%20Day/overview\n",
    "Modelos treinados com dados semanais | https://wandb.ai/breath/BReATH/overview?workspace=user-eltoncn\n",
    "AGs utilizados para otimizar os modelos semanais | https://wandb.ai/breath/BReATH_AG/overview?workspace=user-eltoncn\n",
    "Ensemble treinados para utilizar os outros modelos (Disponível em outro notebook) | https://wandb.ai/breath/BReATH_Ensemble/overview?workspace=user-eltoncn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: eltoncn (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamanho do batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 84959\n",
    "STEPS_PER_EPOCH = int(len(train_features)/BATCH_SIZE)\n",
    "STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class ModelManager:\n",
    "    '''\n",
    "        Gerencia os modelos criados\n",
    "    '''\n",
    "\n",
    "    def __init__(self, project_name, train_features, train_target, val_features, val_target, save_dir=\".\"):\n",
    "        '''\n",
    "            Construtor do ModelManager.\n",
    "\n",
    "            Parâmetros:\n",
    "                project_name: Nome do projeto. Utilizado para logar no wandb.\n",
    "                train_features: Features do conjunto de treino.\n",
    "                train_target: Coluna objetivo do conjunto de treino.\n",
    "                val_features: Features do conjunto de validação.\n",
    "                val_target: Coluna objetivo do conjunto de validação.\n",
    "                save_dir: Diretório para salvar os modelos.\n",
    "        \n",
    "        '''\n",
    "        self._project_name = project_name\n",
    "\n",
    "        self._save_dir = save_dir\n",
    "        self._model_save_dir = self._save_dir+\"\\\\models\"\n",
    "        self._log_dir = self._save_dir+\"\\\\log\"\n",
    "        \n",
    "        self._models : Dict[str, keras.Model] = {}\n",
    "        self._current_model = \"\"\n",
    "\n",
    "        self._architectures = {}\n",
    "        self._hist = {}\n",
    "\n",
    "        self._data = {}\n",
    "        self._data[\"train_features\"] = np.asarray(train_features)\n",
    "        self._data[\"train_target\"] = np.asarray(train_target)\n",
    "        self._data[\"val_features\"] = np.asarray(val_features)\n",
    "        self._data[\"val_target\"] = np.asarray(val_target)\n",
    "\n",
    "        self._sample_features = self._data[\"train_features\"][:10000]\n",
    "        self._sample_target = self._data[\"train_target\"][:10000]\n",
    "        self._sample_x = train_df[\"Dia\"][:10000]\n",
    "\n",
    "    def set_sample(self, sample_features, sample_target, sample_x):\n",
    "        '''\n",
    "            Define os dados para plotar o gráfico exemplo.\n",
    "\n",
    "            Parâmetros:\n",
    "                sample_features: Features para plotar o gráfico.\n",
    "                sapmle_target: Ground truth\n",
    "                sample_x: Dados para utilizar no eixo x do gráfico.\n",
    "        '''\n",
    "        self._sample_features = sample_features\n",
    "        self._sample_target = sample_target\n",
    "        self._sample_x = sample_x\n",
    "\n",
    "    def register_model(self, model, model_name, architecture_name):\n",
    "        '''\n",
    "            Registra um modelo para ser treinado.\n",
    "\n",
    "            Parâmetros:\n",
    "                model: Modelo a ser treinado.\n",
    "                model_name: Nome do modelo.\n",
    "                architecture_name: Nome da arquitetura que o modelo utiliza.\n",
    "        '''\n",
    "\n",
    "        self._current_model = model_name\n",
    "\n",
    "        self._models[model_name] = model\n",
    "        self._architectures[model_name] = architecture_name\n",
    "\n",
    "    def compile_fit_save(self, epochs, optimizer, model_name=None, batch_size=BATCH_SIZE, patience=None, verbose='auto', loss=\"mean_squared_error\", group=None):\n",
    "        '''\n",
    "            Compila, treina e salva o modelo.\n",
    "\n",
    "            Parâmetros:\n",
    "                epochs: Quantidade de epochs que o modelo será treinado.\n",
    "                optimizer: Otimizador que será utilizado.\n",
    "                model_name: Nome do modelo que será treinado. None treina o último modelo registrado.\n",
    "                batch_size: Tamanho do batch.\n",
    "                patience: Paciência do treino. None treina o modelo até a última epoch.\n",
    "                verbose: Verbose do treino.\n",
    "                loss: Função de perda utilizada para o treino.\n",
    "                group: Nome do grupo do modelo (utilizado pelo wandb).\n",
    "        '''\n",
    "        \n",
    "        if model_name is None:\n",
    "            model_name = self._current_model\n",
    "        else:\n",
    "            self._current_model = model_name\n",
    "\n",
    "        learning_rate = optimizer.learning_rate.numpy()\n",
    "        \n",
    "        config = {}\n",
    "        config[\"leaning_rate\"] = learning_rate\n",
    "        config[\"epochs\"] = epochs\n",
    "        config[\"architecture\"] = self._architectures[model_name]\n",
    "        config[\"batch_size\"] = batch_size\n",
    "        config[\"optimizer\"] = optimizer._name\n",
    "        config[\"loss\"] = loss\n",
    "        config[\"patience\"] = patience\n",
    "\n",
    "        run = wandb.init(project=self._project_name, entity=\"breath\",\n",
    "                           config = config, group=group)\n",
    "        \n",
    "        run.name = model_name\n",
    "\n",
    "        metrics = [tf.keras.losses.mean_absolute_error, tf.keras.losses.mean_squared_error]\n",
    "\n",
    "        model = self._models[model_name]\n",
    "        model.compile(optimizer=optimizer, \n",
    "                        loss= tf.keras.losses.get(loss),\n",
    "                        metrics=metrics)\n",
    "        \n",
    "        callbacks = []\n",
    "        callbacks.append(WandbCallback(\"val_mean_squared_error\" ))\n",
    "        #callbacks.append(keras.callbacks.TensorBoard(log_dir=self._log_dir, histogram_freq=1))\n",
    "        \n",
    "        if patience is not None:\n",
    "            callbacks.append(keras.callbacks.EarlyStopping(monitor=\"val_mean_squared_error\", patience=patience))\n",
    "\n",
    "        self._hist[model_name] = model.fit(x=self._data[\"train_features\"], y=self._data[\"train_target\"], \n",
    "                                    validation_data=(self._data[\"val_features\"], self._data[\"val_target\"]),\n",
    "                                    epochs=epochs, batch_size=batch_size,\n",
    "                                    callbacks= callbacks, verbose=verbose)\n",
    "\n",
    "        \n",
    "        self.plot_sample()\n",
    "        wandb.log({\"predictions\":plt})\n",
    "        plt.show()\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    def plot_sample(self, show=False):\n",
    "        '''\n",
    "            Plota o modelo atual com os dados de exemplo.\n",
    "\n",
    "            Parâmetros:\n",
    "                show: Se o gráfico deverá ser mostrado na tela.\n",
    "        '''\n",
    "        model  = self._models[self._current_model]\n",
    "\n",
    "        predictions = model.predict(self._sample_features).flatten()\n",
    "        plt.plot(self._sample_x, self._sample_target)\n",
    "        plt.plot(self._sample_x, predictions)\n",
    "        plt.ylabel(\"Casos/População\")\n",
    "        plt.legend([\"GT\", \"Predito\"])\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def save(self, model_name):\n",
    "        '''\n",
    "            Salva um modelo.\n",
    "\n",
    "            Parâmetros:\n",
    "                model_name: Nome do modelo que vai ser salvo.\n",
    "        '''\n",
    "        self._models[model_name].save(self._model_save_dir+\"\\\\\"+model_name)\n",
    "\n",
    "        try:\n",
    "            keras.models.load_model(self._model_save_dir)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERRO AO SALVAR O MODELO\")\n",
    "    \n",
    "    def load(self, model_name):\n",
    "        '''\n",
    "            Carrega um modelo.\n",
    "\n",
    "            Parâmetros:\n",
    "                model_name: Nome do modelo que vai ser carregado.\n",
    "        '''\n",
    "        self._models[model_name] = keras.models.load_model(self._model_save_dir)\n",
    "\n",
    "        self._current_model = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ModelManager(\"BReATH\", train_features.to_numpy(), train_target.to_numpy(), val_features.to_numpy(), val_target.to_numpy(), save_dir=\".\\\\save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos certificamos que estamos utilizado a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_device = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_device[0],True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, lançamos uma exceção, visto que tivemos que re-executar os passos acima muitas vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8b4075ef66e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Lança exceção (útil para executar todo o notebook até este ponto após falha do tf enquanto treinava algum modelo)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lança exceção (útil para executar todo o notebook até este ponto após falha do tf enquanto treinava algum modelo)\n",
    "\n",
    "raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos parte 1\n",
    "\n",
    "Treinamos alguns modelos com os dados disponíveis. Percebemos posteriormente que utilizar dados diários não forneceu bons modelos, então nenhum modelo treinado aqui foi utilizado, porém as arquiteturas foram retreinadas com os dados semanais posteriormente. Veja a subseção de conclusões no fim dessa seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN\n",
    "\n",
    "Algumas redes neurais treinadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro modelo treinado\n",
    "def create_first():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(100, activation=\"relu\")(input)\n",
    "    x = keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = create_first()\n",
    "\n",
    "manager.register_model(first_model, \"first\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentamos aumentar o modelo\n",
    "\n",
    "def create_larger():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(input)\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_model = create_larger()\n",
    "manager.register_model(larger_model, \"larger\", \"larger\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diminuir o modelo para diminuir o overfitting\n",
    "\n",
    "def create_small():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(100, activation=\"relu\")(input)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "small_model = create_small()\n",
    "manager.register_model(small_model, \"small\", \"small\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "Testamos alguns modelos utilizando LSTMs.\n",
    "\n",
    "É interessante observar que tivemos alguns problemas criando os modelos com LSTM, já que foram os únicos que chegaram a utilizar mais memória que disponível. Tivemos que aumentar a quantidade de batchs na célula anterior para conseguir treinar alguns modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma camada com unidades LSTM\n",
    "def create_first_lstm():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(32)(input)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_first_lstm()\n",
    "manager.register_model(model, \"first_lstm\", \"first_lstm\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descobrindo o uso de return_sequences (gera erro :)\n",
    "def create_lstm2():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(32, return_sequences=True)(input)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_lstm2()\n",
    "manager.register_model(model, \"lstm2\", \"lstm2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duas camadas\n",
    "def create_lstm3():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(32, return_sequences=True)(input)\n",
    "    x = keras.layers.LSTM(32)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_lstm3()\n",
    "manager.register_model(model, \"lstm3\", \"lstm3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN (gera erro tb :), não tínhamos ideia do pq o modelo parecia tão ruim\n",
    "def create_cnn():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Conv1D(32, kernel_size=(3, ))(input)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_cnn()\n",
    "manager.register_model(model, \"cnn1\", \"cnn1\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros testes\n",
    "Tentamos trocar o otimizador, função de ativação, a perda e os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o SGD\n",
    "model = create_first()\n",
    "manager.register_model(model, \"first_sgd\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.SGD(learning_rate=0.0005), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentamos trocar a função de ativação para a sigmoide. Não melhorou os resultados.\n",
    "def create_first_sigmoid():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(100, activation=\"sigmoid\")(input)\n",
    "    x = keras.layers.Dense(100, activation=\"sigmoid\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_first_sigmoid()\n",
    "manager.register_model(model, \"first_sigmoid\", \"first_sigmoid\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentamos aumentar ela, já que pareceu ser treinável por mais tempo.\n",
    "def create_larger_sigmoid():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"sigmoid\")(input)\n",
    "    x = keras.layers.Dense(1000, activation=\"sigmoid\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_larger_sigmoid()\n",
    "manager.register_model(model, \"larger_sigmoid\", \"larger_sigmoid\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM com a sigmoide.\n",
    "def create_lstm_sigmoid():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(32)(input)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_lstm_sigmoid()\n",
    "manager.register_model(model, \"lstm_sigmoid\", \"lstm_sigmoid\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 camadas de LSTM com a sigmoide.\n",
    "def create_lstm_sigmoid2():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(32, return_sequences=True)(input)\n",
    "    x = keras.layers.LSTM(32)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_lstm_sigmoid2()\n",
    "manager.register_model(model, \"lstm_sigmoid2\", \"lstm_sigmoid2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O primeiro modelo, dessa vez utilizando a perda MSLE\n",
    "model = create_first()\n",
    "manager.register_model(model, \"first_log\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, patience=20, loss=\"mean_squared_logarithmic_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentamos remover os dados nulos, já que os gráficos gerados pelos modelos eram sempre nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_zeroless = train_features.to_numpy()\n",
    "train_target_zeroless = train_target.to_numpy()\n",
    "val_features_zeroless = val_features.to_numpy()\n",
    "val_target_zeroless = val_target.to_numpy()\n",
    "\n",
    "mask = train_target_zeroless != 0\n",
    "val_mask = val_target_zeroless != 0\n",
    "\n",
    "train_target_zeroless = train_target_zeroless[mask]\n",
    "train_features_zeroless = train_features_zeroless[mask]\n",
    "val_features_zeroless = val_features_zeroless[val_mask]\n",
    "val_target_zeroless = val_target_zeroless[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitacao</th>\n",
       "      <th>Pressao_at_max</th>\n",
       "      <th>Pressao_at_min</th>\n",
       "      <th>Radiacao</th>\n",
       "      <th>Temp_max</th>\n",
       "      <th>Temp_min</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Max_vent</th>\n",
       "      <th>Velocidade_vent</th>\n",
       "      <th>Pop_estimada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "      <td>1.784139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.245522e-16</td>\n",
       "      <td>-1.432445e-15</td>\n",
       "      <td>2.329507e-14</td>\n",
       "      <td>-1.473959e-15</td>\n",
       "      <td>-1.436714e-15</td>\n",
       "      <td>1.905683e-15</td>\n",
       "      <td>5.725955e-16</td>\n",
       "      <td>-1.154622e-16</td>\n",
       "      <td>-9.053457e-16</td>\n",
       "      <td>-1.784184e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>-3.754402e+00</td>\n",
       "      <td>-3.763698e+00</td>\n",
       "      <td>-2.740855e+00</td>\n",
       "      <td>-5.989725e+00</td>\n",
       "      <td>-6.060539e+00</td>\n",
       "      <td>-3.623111e+00</td>\n",
       "      <td>-2.937551e+00</td>\n",
       "      <td>-1.826297e+00</td>\n",
       "      <td>-3.112124e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>-7.682675e-01</td>\n",
       "      <td>-7.684687e-01</td>\n",
       "      <td>-6.173573e-01</td>\n",
       "      <td>-5.796011e-01</td>\n",
       "      <td>-5.648660e-01</td>\n",
       "      <td>-6.524339e-01</td>\n",
       "      <td>-6.598478e-01</td>\n",
       "      <td>-6.869443e-01</td>\n",
       "      <td>-2.882414e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.060475e-01</td>\n",
       "      <td>2.465197e-02</td>\n",
       "      <td>2.413291e-02</td>\n",
       "      <td>1.036241e-01</td>\n",
       "      <td>1.490688e-01</td>\n",
       "      <td>1.825455e-01</td>\n",
       "      <td>6.375657e-02</td>\n",
       "      <td>-7.367400e-02</td>\n",
       "      <td>-1.347116e-01</td>\n",
       "      <td>-2.394346e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.515670e-01</td>\n",
       "      <td>9.055588e-01</td>\n",
       "      <td>9.042712e-01</td>\n",
       "      <td>7.030119e-01</td>\n",
       "      <td>6.980666e-01</td>\n",
       "      <td>7.321128e-01</td>\n",
       "      <td>7.206848e-01</td>\n",
       "      <td>5.459954e-01</td>\n",
       "      <td>5.740864e-01</td>\n",
       "      <td>-1.117164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.892274e+01</td>\n",
       "      <td>2.317003e+00</td>\n",
       "      <td>2.323264e+00</td>\n",
       "      <td>7.149043e+00</td>\n",
       "      <td>3.233438e+00</td>\n",
       "      <td>4.557101e+00</td>\n",
       "      <td>2.277895e+00</td>\n",
       "      <td>2.342352e+01</td>\n",
       "      <td>1.335032e+01</td>\n",
       "      <td>1.216895e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitacao  Pressao_at_max  Pressao_at_min      Radiacao  \\\n",
       "count  1.784139e+06    1.784139e+06    1.784139e+06  1.784139e+06   \n",
       "mean  -2.245522e-16   -1.432445e-15    2.329507e-14 -1.473959e-15   \n",
       "std    1.000000e+00    1.000000e+00    1.000000e+00  1.000000e+00   \n",
       "min   -3.060475e-01   -3.754402e+00   -3.763698e+00 -2.740855e+00   \n",
       "25%   -3.060475e-01   -7.682675e-01   -7.684687e-01 -6.173573e-01   \n",
       "50%   -3.060475e-01    2.465197e-02    2.413291e-02  1.036241e-01   \n",
       "75%   -2.515670e-01    9.055588e-01    9.042712e-01  7.030119e-01   \n",
       "max    2.892274e+01    2.317003e+00    2.323264e+00  7.149043e+00   \n",
       "\n",
       "           Temp_max      Temp_min       Umidade      Max_vent  \\\n",
       "count  1.784139e+06  1.784139e+06  1.784139e+06  1.784139e+06   \n",
       "mean  -1.436714e-15  1.905683e-15  5.725955e-16 -1.154622e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.989725e+00 -6.060539e+00 -3.623111e+00 -2.937551e+00   \n",
       "25%   -5.796011e-01 -5.648660e-01 -6.524339e-01 -6.598478e-01   \n",
       "50%    1.490688e-01  1.825455e-01  6.375657e-02 -7.367400e-02   \n",
       "75%    6.980666e-01  7.321128e-01  7.206848e-01  5.459954e-01   \n",
       "max    3.233438e+00  4.557101e+00  2.277895e+00  2.342352e+01   \n",
       "\n",
       "       Velocidade_vent  Pop_estimada  \n",
       "count     1.784139e+06  1.784139e+06  \n",
       "mean     -9.053457e-16 -1.784184e-18  \n",
       "std       1.000000e+00  1.000000e+00  \n",
       "min      -1.826297e+00 -3.112124e-01  \n",
       "25%      -6.869443e-01 -2.882414e-01  \n",
       "50%      -1.347116e-01 -2.394346e-01  \n",
       "75%       5.740864e-01 -1.117164e-01  \n",
       "max       1.335032e+01  1.216895e+01  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager._data[\"train_features\"] = train_features_zeroless\n",
    "manager._data[\"train_target\"] = train_target_zeroless\n",
    "manager._data[\"val_features\"] = val_features_zeroless\n",
    "manager._data[\"val_target\"] = val_target_zeroless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28849, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_zeroless.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_first()\n",
    "manager.register_model(model, \"first_zeroless\", \"first_zeroless\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = create_first()\n",
    "\n",
    "manager.register_model(first_model, \"first\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões\n",
    "\n",
    "Todos os modelos treinados até aqui, embora as métricas diminuam, não parecem gerar saídas úteis. Plotando a saída em um conjunto reduzido de dados, os modelos predizeram 0 ou apenas ruído. Concluímos que a alta quantidade de dias com nenhum caso acabou por atrapalhar o modelo. Tentamos então, nos próximos passos, agrupar os dados por semana, aumentando a densidade de casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semanas\n",
    "\n",
    "Aqui, agrupamos os dados por semana para aumentar a densidade de casos em cada entrada.\n",
    "\n",
    "Como já tínhamos trabalhado com agrupamento dos dados por dia utilizando SQL, achamos mais simples reconverter os conjuntos para BDs SQL, realizar o agrupamento e converter de volta para DataFrames do Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos o banco de dados\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"sqlite://\", echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"DROP TABLE IF EXISTS Clima_Casos\")\n",
    "\n",
    "#Convertemos os dados para SQL\n",
    "train_df.to_sql(\"Clima_Casos\", con=engine)\n",
    "\n",
    "# Realizamos a query para agrupar os dados\n",
    "query = \"SELECT Nome_municipio, Sum(Precipitacao) as Precipitacao, Avg(Pressao_at_max) as Pressao_at_max, \"\n",
    "query += \"Avg(Pressao_at_min) as Pressao_at_min, Avg(Radiacao) as Radiacao, Avg(Temp_max) as Temp_max, Avg(Temp_min) as Temp_min, \"\n",
    "query += \"Avg(Umidade) as Umidade, Avg(Max_vent) as Max_vent, Avg(Velocidade_vent) as Velocidade_vent, Pop_estimada, \"\n",
    "query += \" DIA/7 AS Semana, Sum(Casos) as Casos FROM Clima_Casos GROUP BY Nome_municipio, Semana\"\n",
    "\n",
    "train_df_week = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar o histograma de casos, comprovando a hipótese de que agrupar os dados por semana ajudaria a eliminar entradas nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_df_week[\"Casos\"])\n",
    "plt.hist(train_df[\"Casos\"])\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"Quantidade de casos\")\n",
    "plt.ylabel(\"Contagem\")\n",
    "\n",
    "plt.legend([\"Casos por semana\", \"Casos por dia\"])\n",
    "\n",
    "plt.title(\"Histograma - Casos\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos o mesmo processo com o conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"DROP TABLE IF EXISTS Clima_Casos\")\n",
    "\n",
    "val_df.to_sql(\"Clima_Casos\", con=engine)\n",
    "query = \"SELECT Nome_municipio, Sum(Precipitacao) as Precipitacao, Avg(Pressao_at_max) as Pressao_at_max, \"\n",
    "query += \"Avg(Pressao_at_min) as Pressao_at_min, Avg(Radiacao) as Radiacao, Avg(Temp_max) as Temp_max, Avg(Temp_min) as Temp_min, \"\n",
    "query += \"Avg(Umidade) as Umidade, Avg(Max_vent) as Max_vent, Avg(Velocidade_vent) as Velocidade_vent, Pop_estimada, \"\n",
    "query += \" DIA/7 AS Semana, Sum(Casos) as Casos FROM Clima_Casos GROUP BY Nome_municipio, Semana\"\n",
    "\n",
    "val_df_week = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação\n",
    "\n",
    "Separamos novamente os conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "features_names.remove(\"Dia\")\n",
    "\n",
    "train_features = train_df_week[features_names]\n",
    "val_features = val_df_week[features_names]\n",
    "\n",
    "drop_columns = [\"Nome_municipio\"]\n",
    "\n",
    "for column in drop_columns:\n",
    "    train_features.drop(column, axis=\"columns\", inplace=True)\n",
    "    val_features.drop(column, axis=\"columns\", inplace=True)\n",
    "\n",
    "train_target = train_df_week[\"Casos\"]\n",
    "val_target = val_df_week[\"Casos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_features.shape[1]\n",
    "n_target = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização\n",
    "\n",
    "E normalizamos eles, salvando as novas distribuições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = {}\n",
    "\n",
    "for column in train_features.columns:\n",
    "    train_dist[column] = {}\n",
    "    train_dist[column][\"mean\"] = description[column][\"mean\"]\n",
    "    train_dist[column][\"std\"] = description[column][\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train_dist_week.json\", \"w\")\n",
    "json.dump(train_dist, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "for df in [train_features, val_features]:\n",
    "    for column in train_features:\n",
    "        df.loc[:, column] = (df[column]-train_dist[column][\"mean\"])/train_dist[column][\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitacao</th>\n",
       "      <th>Pressao_at_max</th>\n",
       "      <th>Pressao_at_min</th>\n",
       "      <th>Radiacao</th>\n",
       "      <th>Temp_max</th>\n",
       "      <th>Temp_min</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Max_vent</th>\n",
       "      <th>Velocidade_vent</th>\n",
       "      <th>Pop_estimada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "      <td>2.611090e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.750119e-17</td>\n",
       "      <td>-2.420824e-16</td>\n",
       "      <td>4.843389e-15</td>\n",
       "      <td>-1.110596e-15</td>\n",
       "      <td>1.462944e-16</td>\n",
       "      <td>2.586276e-16</td>\n",
       "      <td>5.024515e-16</td>\n",
       "      <td>2.473072e-16</td>\n",
       "      <td>-3.082631e-16</td>\n",
       "      <td>3.047799e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.299823e-01</td>\n",
       "      <td>-3.614769e+00</td>\n",
       "      <td>-3.610927e+00</td>\n",
       "      <td>-3.585174e+00</td>\n",
       "      <td>-5.137426e+00</td>\n",
       "      <td>-5.304860e+00</td>\n",
       "      <td>-4.092521e+00</td>\n",
       "      <td>-4.211235e+00</td>\n",
       "      <td>-2.141092e+00</td>\n",
       "      <td>-3.111794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.299823e-01</td>\n",
       "      <td>-7.667900e-01</td>\n",
       "      <td>-7.658991e-01</td>\n",
       "      <td>-6.134432e-01</td>\n",
       "      <td>-5.791706e-01</td>\n",
       "      <td>-6.178027e-01</td>\n",
       "      <td>-5.919074e-01</td>\n",
       "      <td>-6.064536e-01</td>\n",
       "      <td>-6.777965e-01</td>\n",
       "      <td>-2.880590e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.576515e-01</td>\n",
       "      <td>2.255351e-02</td>\n",
       "      <td>2.214004e-02</td>\n",
       "      <td>2.849036e-02</td>\n",
       "      <td>1.310423e-01</td>\n",
       "      <td>1.588711e-01</td>\n",
       "      <td>1.473996e-01</td>\n",
       "      <td>1.788824e-03</td>\n",
       "      <td>-8.908246e-02</td>\n",
       "      <td>-2.389350e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.316720e-01</td>\n",
       "      <td>9.144444e-01</td>\n",
       "      <td>9.132943e-01</td>\n",
       "      <td>6.453361e-01</td>\n",
       "      <td>6.985784e-01</td>\n",
       "      <td>7.464417e-01</td>\n",
       "      <td>7.238939e-01</td>\n",
       "      <td>6.340860e-01</td>\n",
       "      <td>5.953007e-01</td>\n",
       "      <td>-1.114829e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.408379e+01</td>\n",
       "      <td>2.314561e+00</td>\n",
       "      <td>2.321065e+00</td>\n",
       "      <td>7.770369e+00</td>\n",
       "      <td>3.304806e+00</td>\n",
       "      <td>4.004419e+00</td>\n",
       "      <td>2.653008e+00</td>\n",
       "      <td>7.335062e+00</td>\n",
       "      <td>1.178436e+01</td>\n",
       "      <td>1.225012e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitacao  Pressao_at_max  Pressao_at_min      Radiacao  \\\n",
       "count  2.611090e+05    2.611090e+05    2.611090e+05  2.611090e+05   \n",
       "mean  -7.750119e-17   -2.420824e-16    4.843389e-15 -1.110596e-15   \n",
       "std    1.000000e+00    1.000000e+00    1.000000e+00  1.000000e+00   \n",
       "min   -6.299823e-01   -3.614769e+00   -3.610927e+00 -3.585174e+00   \n",
       "25%   -6.299823e-01   -7.667900e-01   -7.658991e-01 -6.134432e-01   \n",
       "50%   -4.576515e-01    2.255351e-02    2.214004e-02  2.849036e-02   \n",
       "75%    2.316720e-01    9.144444e-01    9.132943e-01  6.453361e-01   \n",
       "max    1.408379e+01    2.314561e+00    2.321065e+00  7.770369e+00   \n",
       "\n",
       "           Temp_max      Temp_min       Umidade      Max_vent  \\\n",
       "count  2.611090e+05  2.611090e+05  2.611090e+05  2.611090e+05   \n",
       "mean   1.462944e-16  2.586276e-16  5.024515e-16  2.473072e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -5.137426e+00 -5.304860e+00 -4.092521e+00 -4.211235e+00   \n",
       "25%   -5.791706e-01 -6.178027e-01 -5.919074e-01 -6.064536e-01   \n",
       "50%    1.310423e-01  1.588711e-01  1.473996e-01  1.788824e-03   \n",
       "75%    6.985784e-01  7.464417e-01  7.238939e-01  6.340860e-01   \n",
       "max    3.304806e+00  4.004419e+00  2.653008e+00  7.335062e+00   \n",
       "\n",
       "       Velocidade_vent  Pop_estimada  \n",
       "count     2.611090e+05  2.611090e+05  \n",
       "mean     -3.082631e-16  3.047799e-17  \n",
       "std       1.000000e+00  1.000000e+00  \n",
       "min      -2.141092e+00 -3.111794e-01  \n",
       "25%      -6.777965e-01 -2.880590e-01  \n",
       "50%      -8.908246e-02 -2.389350e-01  \n",
       "75%       5.953007e-01 -1.114829e-01  \n",
       "max       1.178436e+01  1.225012e+01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = {}\n",
    "target_dist[\"mean\"] = train_target.mean()\n",
    "target_dist[\"std\"] = train_target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"target_dist_week.json\", \"w\")\n",
    "json.dump(target_dist, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: Mais uma vez, avisamos que a normalização do target não é realizada corretamente (a célula não salva o resultado), os targets utilizados não são normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_target, val_target]:\n",
    "    df = (df-target_dist[\"mean\"])/target_dist[\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos parte 2\n",
    "\n",
    "Começamos a treinar modelos utilizando os dados semanais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos um novo manager utilizando os dados semanais.\n",
    "manager = ModelManager(\"BReATH\", train_features.to_numpy(), train_target.to_numpy(), val_features.to_numpy(), val_target.to_numpy(), save_dir=\".\\\\save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, retreinamos duas vezes o primeiro modelo. A ideia era verificar se era melhor continuar usando vários batchs, ou utilizar apenas um. No final, o treino com vários batchs se mostrou melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = create_first()\n",
    "\n",
    "manager.register_model(first_model, \"first_week\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = create_first()\n",
    "\n",
    "manager.register_model(first_model, \"first_week\", \"first\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=train_features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E continuamos a treinar os outros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_model = create_larger()\n",
    "manager.register_model(larger_model, \"larger_week\", \"larger\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_first_lstm()\n",
    "manager.register_model(model, \"first_lstm_week\", \"first_lstm\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger2():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(input)\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger2()\n",
    "manager.register_model(model, \"larger2_week\", \"larger2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões\n",
    "\n",
    "Os modelos estão ficando melhores, e a saída parece fazer algum sentido. Mas, a visualização não estava muito adequada, já que plotávamos junto muitas cidades que não tinham muitos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando forma de plotar amostra\n",
    "\n",
    "Para melhorar o problema de visualização, decidimos alterar a forma de mostrar um exemplo das predições. Decidimos por sempre plotar as predições para a cidade com maior quantidade de casos no conjunto de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes com o novo método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(train_features)\n",
    "\n",
    "index = np.argmax(train_df_week[\"Casos\"])\n",
    "municipio = train_df_week[\"Nome_municipio\"].iloc[index]\n",
    "\n",
    "mask = train_df_week[\"Nome_municipio\"] == municipio\n",
    "mask = mask.to_numpy()\n",
    "\n",
    "plt.plot(train_df_week[\"Semana\"][mask], train_target[mask])\n",
    "plt.plot(train_df_week[\"Semana\"][mask], prediction[mask])\n",
    "\n",
    "plt.suptitle(\"Predição do modelo\")\n",
    "plt.title(municipio)\n",
    "plt.legend([\"GT\", \"Predito\"])\n",
    "plt.xlabel(\"Semana\")\n",
    "plt.ylabel(\"Casos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(val_df_week[\"Casos\"])\n",
    "municipio = val_df_week[\"Nome_municipio\"].iloc[index]\n",
    "\n",
    "mask = val_df_week[\"Nome_municipio\"] == municipio\n",
    "mask = mask.to_numpy()\n",
    "\n",
    "features = val_features[mask]\n",
    "\n",
    "prediction = model.predict(features)\n",
    "\n",
    "plt.plot(val_df_week[\"Semana\"][mask], val_target[mask])\n",
    "plt.plot(val_df_week[\"Semana\"][mask], prediction)\n",
    "\n",
    "plt.suptitle(\"Predição do modelo\")\n",
    "plt.title(municipio)\n",
    "plt.legend([\"GT\", \"Predito\"])\n",
    "plt.xlabel(\"Semana\")\n",
    "plt.ylabel(\"Casos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualizamos o manager para utilizar esse método de sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(val_df_week[\"Casos\"])\n",
    "municipio = val_df_week[\"Nome_municipio\"].iloc[index]\n",
    "\n",
    "mask = val_df_week[\"Nome_municipio\"] == municipio\n",
    "mask = mask.to_numpy()\n",
    "\n",
    "features = val_features[mask]\n",
    "\n",
    "manager = ModelManager(\"BReATH\", train_features.to_numpy(), train_target.to_numpy(), val_features.to_numpy(), val_target.to_numpy(), save_dir=\".\\\\save\")\n",
    "manager.set_sample(features, val_target[mask], val_df_week[\"Semana\"][mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mais modelos\n",
    "\n",
    "E continuamos a testar arquiteturas e otimizadores. Mais especificamente, começamos a aumentar o tamanho da LSTM enquanto tivemos melhoras no conjunto de treino, sem um overfitting muito grande (mas, como todos os modelos, com overfitting), com esperança de conseguir melhorar depois utilizando regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm3()\n",
    "manager.register_model(model, \"lstm3_week\", \"lstm3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm3()\n",
    "manager.register_model(model, \"lstm3_week_sgd\", \"lstm3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.SGD(), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm3()\n",
    "manager.register_model(model, \"lstm3_week_sgd2\", \"lstm3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.SGD(learning_rate=0.01/2.0), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm4():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(64, return_sequences=True)(input)\n",
    "    x = keras.layers.LSTM(64)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm4()\n",
    "manager.register_model(model, \"lstm4_week\", \"lstm4\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm5():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(64, return_sequences=True)(input)\n",
    "    x = keras.layers.LSTM(48, return_sequences=True)(x)\n",
    "    x = keras.layers.LSTM(32)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm5()\n",
    "manager.register_model(model, \"lstm5_week\", \"lstm5\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm6():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.LSTM(64, return_sequences=True)(input)\n",
    "    x = keras.layers.LSTM(48)(x)\n",
    "\n",
    "    x = keras.layers.Dense(500, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm6()\n",
    "manager.register_model(model, \"lstm6_week\", \"lstm6\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm7():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(500, activation=\"relu\")(input)\n",
    "\n",
    "    x = keras.layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = keras.layers.LSTM(48)(x)\n",
    "\n",
    "    x = keras.layers.Dense(500, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm7()\n",
    "manager.register_model(model, \"lstm7_week\", \"lstm7\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testamos uma LSTM com skip. Como o modelo totalmente conectado e a LSTM tiveram resultados interessantes, talvez utilizar um modelo que guardasse a relação temporal e a relação instantânea fosse interessante.\n",
    "\n",
    "Foi o modelo com maior overfitting de todos, então abandonamos a ideia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm8():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x1 = keras.layers.Dense(500, activation=\"relu\")(input)\n",
    "\n",
    "    x2 = keras.layers.LSTM(64, return_sequences=True)(x1)\n",
    "    x2 = keras.layers.LSTM(48)(x2)\n",
    "\n",
    "    x1 = keras.layers.Flatten()(x1)\n",
    "\n",
    "    x = keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    x = keras.layers.Dense(500, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(create_lstm8())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm8()\n",
    "manager.register_model(model, \"lstm8_week\", \"lstm8\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm9():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(input)\n",
    "\n",
    "    x = keras.layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = keras.layers.LSTM(48)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm9()\n",
    "manager.register_model(model, \"lstm9_week\", \"lstm9\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização\n",
    "\n",
    "Até agora, tivemos bons resultados, reduzindo principalmente as métricas de treino. Porém, ainda tínhamos um overfitting muito alto. Tentamos acrescentar regularização L2 e dropout nos modelos treinados anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização - LSTM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm9_reg():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    #FULL\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0005))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #LSTM\n",
    "    x = keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.0005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(48, kernel_regularizer=keras.regularizers.l2(0.0005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #FULL\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #OUT\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm9_reg()\n",
    "manager.register_model(model, \"lstm9_reg_week\", \"lstm9_reg\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm9_reg2():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    #FULL\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #LSTM\n",
    "    x = keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(48, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #FULL\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    #OUT\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm9_reg2()\n",
    "manager.register_model(model, \"lstm9_reg2_week\", \"lstm9_reg2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização - Larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger_reg():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.0005))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.0005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg()\n",
    "manager.register_model(model, \"larger_reg_week\", \"larger_reg\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger_reg2():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.005))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg2()\n",
    "manager.register_model(model, \"larger_reg2_week\", \"larger_reg2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger_reg3():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.05))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.05))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg3()\n",
    "manager.register_model(model, \"larger_reg3_week\", \"larger_reg3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger_reg4():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.1))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.1))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg4()\n",
    "manager.register_model(model, \"larger_reg4_week\", \"larger_reg4\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg4()\n",
    "manager.register_model(model, \"larger_reg4_week_200\", \"larger_reg4\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger_reg5():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.5))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(1000, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.5))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg5()\n",
    "manager.register_model(model, \"larger_reg5_week_200\", \"larger_reg5\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=200, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização - LSTM7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm7_reg():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(500, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.05))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.05))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(48, kernel_regularizer=keras.regularizers.l2(0.05))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(500, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.05))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm7_reg()\n",
    "manager.register_model(model, \"lstm7_reg_week\", \"lstm7_reg\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm7_reg2():\n",
    "    input = keras.Input(shape=(n_features,1), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(500, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.005))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.LSTM(48, kernel_regularizer=keras.regularizers.l2(0.005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(500, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.005))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm7_reg2()\n",
    "manager.register_model(model, \"lstm7_reg2_week\", \"lstm7_reg2\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo genético\n",
    "\n",
    "Já tivemos vários modelos promissores, porém estávamos até agora realizando mudanças de forma errática nos modelos. Tentamos então automatizar o processo.\n",
    "\n",
    "Como a arquitetura com treino mais rápido e com melhor métricas até então foi utilizar duas camadas densas, decidimos utilizar essa arquitetura para otimizar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos por importar de uma outra disciplina o primeiro AG simples que tínhamos criado. Ele suporta mudança dinâmica na taxa de mutação, porém os testes foram executados em poucas gerações, o que inviabiliza utilizar esse recurso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "# Criamos funções para crossover utilizando média e one point.\n",
    "\n",
    "@numba.njit\n",
    "def mean(individual1, individual2):\n",
    "    return (individual1+individual2)/2.0\n",
    "    \n",
    "@numba.njit\n",
    "def one_point(individual1, individual2):\n",
    "    index = np.random.randint(individual1.shape[0])\n",
    "\n",
    "    new_individual = np.empty_like(individual1)\n",
    "    new_individual[:index] = individual1[:index]\n",
    "    new_individual[index:] = individual2[index:]\n",
    "\n",
    "    return new_individual\n",
    "\n",
    "# Mutação\n",
    "\n",
    "@numba.njit\n",
    "def mutation(individual, chromosome_size, mutation_rate, mutation_range):\n",
    "    #Alterar para poder mutacionar apenas um gene\n",
    "    if np.random.rand() < mutation_rate:\n",
    "        individual += (2.0*(np.random.rand(chromosome_size)-0.5))*mutation_range\n",
    "    \n",
    "    return individual\n",
    "\n",
    "\n",
    "# Classe principal para o AG\n",
    "class AG:\n",
    "\n",
    "        \n",
    "    def __init__(self, population_size, mutation_rate, mutation_range, \n",
    "                cross_over = mean, dtype=np.float32, mutation_patience=5, exploration_patience=2, refinement_patience=2, dynamic_rate=True, dynamic_range=True):\n",
    "        '''\n",
    "            Parameters:\n",
    "                mutation_patience: gerações que espera antes de determinar que está parado\n",
    "                refinement_patience: ciclos de refinamento (diminuir taxa/range) que irá esperar antes de iniciar uma exploração para outro mínimo \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #Colocar opção default que mutation_rate=1\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_range = mutation_range\n",
    "        self.mutation_patience = mutation_patience\n",
    "        self.refinement_patience = refinement_patience\n",
    "        self.exploration_patience = exploration_patience\n",
    "        self.dtype = dtype\n",
    "        self.cross_over = cross_over\n",
    "        self.dynamic_rate = dynamic_rate\n",
    "        self.dynamic_range = dynamic_range\n",
    "        \n",
    "        self.mutation = mutation\n",
    "\n",
    "        self.initial_mutation_rate =  mutation_rate\n",
    "        self.initial_mutation_range = mutation_range\n",
    "    \n",
    "    # Seleção por torneio\n",
    "    def selection(self): #tournament\n",
    "        index1 = np.random.randint(self.population_size)\n",
    "        index2 = np.random.randint(self.population_size)\n",
    "\n",
    "        if self.fitness_scores[index1] > self.fitness_scores[index2]:\n",
    "            return self.population[index1]\n",
    "        return self.population[index2]\n",
    "\n",
    "    # Cria uma nova população\n",
    "    def new_population(self):\n",
    "        new_population = np.zeros_like(self.population)\n",
    "        \n",
    "        best_fitness = np.argmax(self.fitness_scores)\n",
    "        best_individual = self.population[best_fitness]\n",
    "\n",
    "        self.individual_best_hist[self.current_generation] = best_individual\n",
    "        self.fitness_best_hist[self.current_generation] = self.fitness_scores[best_fitness]\n",
    "        self.fitness_mean_hist[self.current_generation] = np.mean(self.fitness_scores)\n",
    "        self.fitness_std_hist[self.current_generation] = np.std(self.fitness_scores)\n",
    "\n",
    "\n",
    "        new_population[0] = best_individual\n",
    "\n",
    "        for i in range(1, self.population_size):\n",
    "            father1 = self.selection()\n",
    "            father2 = self.selection()\n",
    "\n",
    "            new_individual = self.cross_over(father1, father2)\n",
    "            new_individual = self.mutation(new_individual, self.chromosome_size, self.mutation_rate, self.mutation_range)\n",
    "\n",
    "            new_population[i] = new_individual\n",
    "        \n",
    "        return new_population\n",
    "        \n",
    "    # Realiza a otimização\n",
    "    def optimize(self, fitness_function, chromosome_size, max_cromossome_value, min_cromossome_value, n_generation):\n",
    "        self.chromosome_size = chromosome_size\n",
    "\n",
    "        self.stopped_count = 0\n",
    "        self.refinement_count = 0\n",
    "        self.exploration_count = 0\n",
    "\n",
    "        self.population = np.random.rand(self.population_size, self.chromosome_size).astype(self.dtype)\n",
    "        self.population *= max_cromossome_value-min_cromossome_value\n",
    "        self.population += min_cromossome_value\n",
    "\n",
    "        self.fitness_scores = np.zeros(self.population_size)\n",
    "\n",
    "        self.individual_best_hist = np.zeros((n_generation, chromosome_size))\n",
    "        self.fitness_best_hist = np.zeros(n_generation)\n",
    "        self.fitness_mean_hist = np.zeros(n_generation)\n",
    "        self.fitness_std_hist = np.zeros(n_generation)\n",
    "        self.mutation_range_hist = np.zeros(n_generation)\n",
    "        self.mutation_rate_hist = np.zeros(n_generation)\n",
    "        self.generation_type = np.zeros(n_generation+1)\n",
    "\n",
    "        self.current_generation = 0\n",
    "\n",
    "        for i in range(n_generation):\n",
    "            print(\"Iniciando geração\", i)\n",
    "            for j in range(self.population_size):\n",
    "                self.fitness_scores[j] = fitness_function(self.population[j])\n",
    "\n",
    "            self.population = self.new_population()\n",
    "\n",
    "            self.mutation_range_hist[self.current_generation] = self.mutation_range\n",
    "            self.mutation_rate_hist[self.current_generation] = self.mutation_rate\n",
    "\n",
    "            if i > 0:\n",
    "                if(abs(self.fitness_best_hist[i] - self.fitness_best_hist[i-1]) < 1E-4):\n",
    "                    self.stopped_count += 1\n",
    "                else:\n",
    "                    self.stopped_count = 0\n",
    "            \n",
    "            self.current_generation += 1\n",
    "\n",
    "            if self.stopped_count > self.mutation_patience:\n",
    "                # Para -> Refina -> Para -> Explora -> Reset\n",
    "                if (self.exploration_count > self.exploration_patience and \n",
    "                    self.refinement_count > self.refinement_patience):\n",
    "                    #Reset\n",
    "                        self.mutation_rate = self.initial_mutation_rate\n",
    "                        self.mutation_range = self.initial_mutation_range\n",
    "\n",
    "                        self.refinement_count = 0\n",
    "                        self.exploration_count = 0\n",
    "                        \n",
    "                elif self.refinement_count > self.refinement_patience:\n",
    "                    if self.exploration_count == 0:\n",
    "                        # 1ª iteração de exploração\n",
    "                        self.mutation_rate = self.initial_mutation_rate\n",
    "                        self.mutation_range = self.initial_mutation_range\n",
    "                    \n",
    "                    #Exploração \n",
    "                    if self.dynamic_rate:\n",
    "                        self.mutation_rate *= 2.0\n",
    "                    if self.dynamic_range:\n",
    "                        self.mutation_range *= 2.0\n",
    "    \n",
    "                    self.exploration_count += 1\n",
    "                    self.generation_type[self.current_generation] = 1\n",
    "                \n",
    "                else:\n",
    "                    #Refinamento\n",
    "                    if self.dynamic_rate:\n",
    "                        self.mutation_rate /= 2.0\n",
    "                    if self.dynamic_range:\n",
    "                        self.mutation_range /= 2.0\n",
    "                    \n",
    "                    self.refinement_count += 1\n",
    "\n",
    "                    self.generation_type[self.current_generation] = -1\n",
    "\n",
    "                self.stopped_count = 0\n",
    "            \n",
    "\n",
    "            \n",
    "    # Plota o histórico de fitness\n",
    "    def plot_fitness(self, max_value = None, min_value = None, min_generation=0, log=False):\n",
    "        plt.plot(np.arange(self.current_generation)[min_generation:], self.fitness_best_hist[min_generation:])\n",
    "        plt.plot(np.arange(self.current_generation)[min_generation:], self.fitness_mean_hist[min_generation:])\n",
    "        \n",
    "        plt.legend([\"Best individual\", \"Mean\"])\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "\n",
    "        if max_value is None:\n",
    "            max_value = self.fitness_best_hist[-1] + (self.fitness_best_hist[-1]/2.0)\n",
    "\n",
    "        plt.ylim(bottom = min_value, top=max_value)\n",
    "\n",
    "        if log:\n",
    "            plt.yscale(\"log\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    # Plota os indivíduos    \n",
    "    def plot_individual(self):\n",
    "        plt.title(\"Best individuals\")\n",
    "\n",
    "        for i in range(self.chromosome_size):\n",
    "            plt.plot(np.arange(self.current_generation), self.individual_best_hist[: , i], label=\"x\"+str(i))\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Gene\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    # Plota os genes\n",
    "    def plot_gene(self):\n",
    "        fig, ax = plt.subplots(self.chromosome_size, 2, figsize=(10,10))\n",
    "\n",
    "        for i in range(self.chromosome_size):\n",
    "            ax[i][0].set_title(\"x\"+str(i))\n",
    "            ax[i][0].plot(np.arange(self.current_generation), self.individual_best_hist[: , i])\n",
    "            ax[i][0].legend([\"x\"+str(i)])\n",
    "            #ax[i][0].set_xlabel(\"Generation\")\n",
    "\n",
    "            ax[i][1].set_title(\"x\"+str(i)+\" - last generations\")\n",
    "            ax[i][1].plot(np.arange(self.current_generation)[50:], self.individual_best_hist[self.current_generation//2: , i])\n",
    "            ax[i][1].legend([\"x\"+str(i)])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    #As próximas funções de plot são apenas úteis para os verificar a taxa de mutação dinâmica\n",
    "    def plot_generation_type(self):\n",
    "        plt.title(\"Generation Type\")\n",
    "        plt.plot(self.generation_type)\n",
    "        plt.xlabel(\"Geração\")\n",
    "        plt.ylabel(\"Tipo\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_mutation_range(self):\n",
    "        plt.title(\"Mutation range\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Mutation Range\")\n",
    "\n",
    "        plt.plot(np.arange(self.current_generation), self.mutation_range_hist)\n",
    "\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_mutation_rate(self):\n",
    "        plt.title(\"Mutation rate\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Mutation Rate\")\n",
    "\n",
    "        plt.plot(np.arange(self.current_generation), self.mutation_rate_hist)\n",
    "\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recriamos as funções de plot, dessa vez sem mostrar o gráfico, para conseguir realizar logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitness(self, max_value = None, min_value = None, min_generation=0, log=False):\n",
    "    plt.plot(np.arange(self.current_generation)[min_generation:], self.fitness_best_hist[min_generation:])\n",
    "    plt.plot(np.arange(self.current_generation)[min_generation:], self.fitness_mean_hist[min_generation:])\n",
    "    \n",
    "    plt.legend([\"Best individual\", \"Mean\"])\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "\n",
    "    if max_value is None:\n",
    "        max_value = self.fitness_best_hist[-1] + (self.fitness_best_hist[-1]/2.0)\n",
    "\n",
    "    plt.ylim(bottom = min_value, top=max_value)\n",
    "\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "def plot_individual(self):\n",
    "    plt.title(\"Best individuals\")\n",
    "\n",
    "    for i in range(self.chromosome_size):\n",
    "        plt.plot(np.arange(self.current_generation), self.individual_best_hist[: , i], label=\"x\"+str(i))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Gene\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loga os dados do AG no wandb\n",
    "def log_ag(name, ag, chromosome_size, max_cromossome_value, min_cromossome_value, n_generation):\n",
    "\n",
    "    config = {}\n",
    "    config[\"population_size\"] = ag.population_size\n",
    "    config[\"mutation_rate\"] = ag.mutation_rate\n",
    "    config[\"mutation_range\"] = ag.mutation_range\n",
    "    config[\"mutation_patience\"] = ag.mutation_patience\n",
    "    config[\"refinement_patience\"] = ag.refinement_patience\n",
    "    config[\"exploration_patience\"] = ag.exploration_patience\n",
    "    config[\"dynamic_rate\"] = ag.dynamic_rate\n",
    "    config[\"chromosome_size\"] = chromosome_size\n",
    "    config[\"max_cromossome_value\"] = max_cromossome_value\n",
    "    config[\"min_cromossome_value\"] = min_cromossome_value\n",
    "    config[\"n_generation\"] = n_generation\n",
    "    config[\"cross_over\"] = ag.cross_over.__name__\n",
    "\n",
    "    run = wandb.init(project=\"BReATH_AG\", entity=\"breath\",\n",
    "                        config = config)\n",
    "\n",
    "    run.name = name\n",
    "\n",
    "    for i in range(ag.fitness_best_hist.shape[0]):\n",
    "        log_dict = {\"fitness_best\": ag.fitness_best_hist[i],\n",
    "                    \"fitness_mean\": ag.fitness_mean_hist[i],\n",
    "                    \"fitness_std\": ag.fitness_std_hist[i],\n",
    "                    \"mutation_range\": ag.mutation_range_hist[i],\n",
    "                    \"mutation_rate\": ag.mutation_rate_hist[i],\n",
    "                    }\n",
    "\n",
    "        for j in range(chromosome_size):\n",
    "            log_dict[\"individual_best_\"+str(j)] =  ag.individual_best_hist[i][j]\n",
    "\n",
    "        \n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    #plot_fitness(ag)\n",
    "    #wandb.log({\"fitness_plot\":plt})\n",
    "    #plt.show()\n",
    "\n",
    "    #plot_individual(ag)\n",
    "    #wandb.log({\"individual_plot\":plt})\n",
    "    #plt.show()\n",
    "\n",
    "    wandb.log({\"fitness_best\": ag.fitness_best_hist})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso primeiro teste. Tentamos otimizar apenas a quantidade de neurônios do modelo. A função para calcular o fitness utilizada foi treinar o modelo por 60 ou 100 gerações (dependendo do experimento), e calcular a média o MSE de validação das últimas gerações, para evitar ruído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_hist = {}\n",
    "\n",
    "def optimize_larger(individual:np.ndarray):\n",
    "    ind = individual.astype(int)\n",
    "    name = str(ind[0])+\"_\"+str(ind[1])\n",
    "    arch_name = \"larger_ag_\"+name\n",
    "    model_name = arch_name+\"_week\"\n",
    "\n",
    "    if name in fitness_hist:\n",
    "        return fitness_hist[name]\n",
    "\n",
    "\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(ind[0], activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.05))(input)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "\n",
    "    x = keras.layers.Dense(ind[1], activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(0.05))(x)\n",
    "    x = tf.keras.layers.Dropout(0.7)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    manager.register_model(model, model_name,  arch_name)\n",
    "    manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=60, batch_size=int(BATCH_SIZE/7))\n",
    "\n",
    "    fitness = np.mean(manager._hist[model_name].history[\"val_mean_squared_error\"][-10:])\n",
    "\n",
    "    fitness_hist[name] = fitnessa\n",
    "\n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AG(10, 1, 10)\n",
    "ag.optimize(optimize_larger, 2, 1500, 100, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbnElEQVR4nO3deZRdZZ3u8e/TGSgIkUxlhFQwUUoUaGSocJm6pYmRQUhyV9NcZEiErA7atFdFhehFhkUPeK8tik2jadJaoRWIqBAckDQBWu+VQAUiQwJS0gwVMxRJJZBAIITf/WO/tTlUqpJTSe1zqDrPZ61aZ+/33cPvwEo9td89KSIwMzMD+JNqF2BmZu8cDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMy6IenPJD21G+uHpAPS9HckfbWMdfaXtEnSoB76r5T077taU0/1mZVyKNg7mqRnJb2afll2SPq5pPF9tN2P9tQfEb+OiAN3dz9pW5+KiKvLWO75iNg7Irb1xX7NdoVDwfqD0yNib2BfYA3w7SrXYzZgORSs34iILcBtwEGdbZL2kPR1Sc9LWpOGavZMfWMk/UzSBknrJf1a0p9IugnYH7gzHYFc0nVfkk6Q1FYy/6ykL0p6VNJGSbdKqivp/5KkVZL+KOmCLtv6vqS/S9MrJJ1W0jdYUrukIyRNSMM6g1PfREn3S3pZ0iJgTE/1ldT40TR9lKTfpu++StI/Sxra3X9XSadKWp72s1LSF8v432EDlEPB+g1JewH/A3igpPka4APAYcABwDjg8tT3BaANqAfGAl8BIiLOA54nHYFExP8us4QzgZOBicChwCdTXScDXwSmAI1Aj8NSwM3AJ0rmTwJejIiHu1n2h8BSsjC4GphZZp0A24DPp3WPASYDf9PDsvOACyNiOHAIsLgX+7EBZnC1CzArw+2S3gCGAe1kv0iRJGA2cGhErE9t/0D2y/TLwFayIaf3RkQr8OvdrOO6iPhj2s+dZEEEWVh8LyIeT31X8vZf/KV+CDwiaa+IeAU4mywo3kbS/sAk4KMR8Rrwn2mfZYmIpSWzz0r6LvAR4JvdLL4VOEjS7yKiA+godz828PhIwfqD6RExAqgD/ha4X9J7yI4A9gKWpmGSDcBdqR3g/wCtwN2SnpE0ZzfrWF0y/Qqwd5reD3ihpO+5njaQwmkFcHo68plKFhRd7Qd0RMTmcrbblaQPpKGz1ZJeAv6BkuGnLv4SOBV4Lg1XHVPufmzgcShYvxER2yLiJ2RDI8cDLwKvAgdHxIj0s086KU1EvBwRX4iI95H98r1Y0uTOzfVhaauA0iui9t/J8p1DSNOA5SkoutvmSEnDetjuZrJABCBdxlpf0n8D8CTQGBHvIhs6U3fFRMRDETENeDdwO7BgJ/XbAOZQsH5DmWnASGBFRLwJ/CtwraR3p2XGSeocXjpN0gFpmGkjWZi8mTa3BnhfH5W2APikpIPSX/9X7GT5W4CPAZ+m+6MEIuI5oAW4StJQSccDp5cs8nugTtLHJQ0BLgP2KOkfDrwEbJL0wbSv7aRtnyNpn4jYmtZ5s7tlrTY4FKw/uFPSJrJfWH8PzIyIJ1LfpWRDRA+kYZL/ADrvL2hM85uA3wL/EhH3pr5/BC5Lw067dbVNRPySbKx+caplhydqI2JVqudY4NYdLHo28N+A9WRBM79kGxvJThzfCKwkO3IovRrpi2n9l8mCc0f7OY/svMNLwKeAc3ZUvw1s8kt2zMysk48UzMws51AwM7OcQ8HMzHIOBTMzy/XrO5rHjBkTEyZMqHYZZmb9ytKlS1+MiPru+vp1KEyYMIGWlpZql2Fm1q9I6vHueA8fmZlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeX69X0Ku+qqO59g+R9fqnYZZma77KD93sUVpx/c59v1kYKZmeVq8kihiHQ1MxsIfKRgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZma5QkNB0uclPSHpcUk3S6qTNFHSEkmtkm6VNDQtu0eab039E4qszczMtldYKEgaB/xPoCkiDgEGAWcBXwOujYgDgA5gVlplFtCR2q9Ny5mZWQUVPXw0GNhT0mBgL2AVcCJwW+pvBqan6WlpntQ/WZIKrs/MzEoUFgoRsRL4OvA8WRhsBJYCGyLijbRYGzAuTY8DXkjrvpGWH911u5JmS2qR1NLe3l5U+WZmNanI4aORZH/9TwT2A4YBJ+/udiNibkQ0RURTfX397m7OzMxKFDl89FHgvyKiPSK2Aj8BjgNGpOEkgAZgZZpeCYwHSP37AOsKrM/MzLooMhSeB46WtFc6NzAZWA7cC5yRlpkJ3JGmF6Z5Uv/iiIgC6zMzsy6KPKewhOyE8cPAY2lfc4FLgYsltZKdM5iXVpkHjE7tFwNziqrNzMy6p/78x3hTU1O0tLRUuwwzs35F0tKIaOquz3c0m5lZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZma5wkJB0oGSlpX8vCTpc5JGSVok6en0OTItL0nXSWqV9KikI4qqzczMuldYKETEUxFxWEQcBhwJvAL8FJgD3BMRjcA9aR7gFKAx/cwGbiiqNjMz616lho8mA3+IiOeAaUBzam8GpqfpacD8yDwAjJC0b4XqMzMzKhcKZwE3p+mxEbEqTa8GxqbpccALJeu0pTYzM6uQwkNB0lBgKvCjrn0REUD0cnuzJbVIamlvb++jKs3MDCpzpHAK8HBErEnzazqHhdLn2tS+Ehhfsl5DanubiJgbEU0R0VRfX19g2WZmtacSofAJ3ho6AlgIzEzTM4E7StpnpKuQjgY2lgwzmZlZBQwucuOShgFTgAtLmq8BFkiaBTwHnJnafwGcCrSSXal0fpG1mZnZ9goNhYjYDIzu0raO7GqkrssGcFGR9ZiZ2Y75jmYzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLFdoKEgaIek2SU9KWiHpGEmjJC2S9HT6HJmWlaTrJLVKelTSEUXWZmZm2yv6SOFbwF0R8UHgw8AKYA5wT0Q0AvekeYBTgMb0Mxu4oeDazMysi8JCQdI+wJ8D8wAi4vWI2ABMA5rTYs3A9DQ9DZgfmQeAEZL2Lao+MzPbXpFHChOBduB7kh6RdKOkYcDYiFiVllkNjE3T44AXStZvS21mZlYhRYbCYOAI4IaIOBzYzFtDRQBERADRm41Kmi2pRVJLe3t7nxVrZmbFhkIb0BYRS9L8bWQhsaZzWCh9rk39K4HxJes3pLa3iYi5EdEUEU319fWFFW9mVosKC4WIWA28IOnA1DQZWA4sBGamtpnAHWl6ITAjXYV0NLCxZJjJzMwqYHDB2/8M8ANJQ4FngPPJgmiBpFnAc8CZadlfAKcCrcAraVkzM6ugQkMhIpYBTd10Te5m2QAuKrIeMzPbMd/RbGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmuaIfc2Fm1q9t3bqVtrY2tmzZUu1Seq2uro6GhgaGDBlS9joOBTOzHWhra2P48OFMmDABSdUup2wRwbp162hra2PixIllr+fhIzOzHdiyZQujR4/uV4EAIInRo0f3+gjHoWBmthP9LRA67UrdDgUzs36oubmZxsZGGhsbaW5u3vkKZfI5BTOzfmb9+vVcddVVtLS0IIkjjzySqVOnMnLkyN3edllHCpLGSpon6Zdp/qD0khwzMyvQQw89xKGHHsqWLVvYvHkzBx98MNdffz1Tpkxh1KhRjBw5kilTpnDXXXf1yf7KPVL4PvA94H+l+d8DtwLz+qQKM7N+4Ko7n2D5H1/q020etN+7uOL0g3vsnzRpElOnTuWyyy7j1Vdf5dxzz2XIkCGMH//WK+0bGhpYuXK7V9rvknLPKYyJiAXAmwAR8QawrU8qMDOzHbr88stZtGgRLS0tXHLJJYXuq9wjhc2SRgMBIOloYOPOVpL0LPAyWYC8ERFNkkaRHWVMAJ4FzoyIDmWnyb9F9p7mV4BPRsTDvfo2ZmYF2tFf9EVat24dmzZtYuvWrWzZsoVx48Zx33335f1tbW2ccMIJfbKvco8ULgYWAu+X9H+B+cBnylz3LyLisIjofFfzHOCeiGgE7knzAKcAjelnNnBDmds3MxvQLrzwQq6++mrOOeccLr30Uk466STuvvtuOjo66Ojo4O677+akk07qk32VdaQQEQ9L+ghwICDgqYjYuov7nAackKabgfuAS1P7/IgI4AFJIyTtGxGrdnE/Zmb93vz58xkyZAhnn30227Zt49hjj2XZsmV89atfZdKkSUA2vDRq1Kg+2V9vLkk9imzIZzBwhCQiYv5O1gngbkkBfDci5gJjS37RrwbGpulxwAsl67alNoeCmdWsGTNmMGPGDAAGDRrEkiVL8r4LLrigz/dXVihIugl4P7CMt04wB9kw0o4cHxErJb0bWCTpydLOiIgUGGWTNJtseIn999+/N6uamdlOlHuk0AQclIZ2yhYRK9PnWkk/JTvaWNM5LCRpX2BtWnwlML5k9YbU1nWbc4G5AE1NTb2qx8zMdqzcE82PA+/pzYYlDZM0vHMa+FjazkJgZlpsJnBHml4IzFDmaGCjzyeYmVVWuUcKY4Dlkh4EXutsjIipO1hnLPDT9ECmwcAPI+IuSQ8BC9Id0c8BZ6blf0F2OWor2SWp5/fmi5iZ2e4rNxSu7O2GI+IZ4MPdtK8DJnfTHsBFvd2PmZn1nXIvSb1f0nuBxoj4D0l7AYOKLc3MzCqt3Afi/TVwG/Dd1DQOuL2gmszMbCdOPvlkRowYwWmnndan2y33RPNFwHHASwAR8TTw7j6txMzMyvalL32Jm266qc+3W24ovBYRr3fOSBpMeg6SmZkVp7tHZz/++ONMnjyZ4cOH9/n+yj3RfL+krwB7SpoC/A1wZ59XY2b2TvbLObD6sb7d5nv+FE65psfu7h6dfcghh/RtDSXKDYU5wCzgMbK7iX8eETcWVpWZmeUuv/xyJk2aRF1dHdddd12h+9phKEiaBjRExPXAv6YTzvXAkZI2RMRthVZnZvZOsoO/6IvU9dHZw4YNK2xfOzuncAnZncadhgJHkj3l9NMF1WRmZiW6Pjq7SDsbPhoaEaVPLv1NRKwH1qdHV5iZWYG6e3T24sWLueKKK3jyySfZtGkTDQ0NzJs3r0/eqaAdPeNOUmtEHNBD3x8i4v27XcFuaGpqipaWlmqWYGYD3IoVK/jQhz5U7TJ2WXf1S1pa8uKzt9nZ8NGSdB6h6wYvBB7c5SrNzOwdaWfDR58Hbpd0NtD5vuQjgT2A6QXWZWZmVbDDUIiItcCxkk4EOt9Y/fOIWFx4ZWZmVnHlPhBvMeAgMLOaFBGk1wD0K718LxpQ/mMuzMxqUl1dHevWrdulX7DVFBGsW7eOurq6Xq1X7h3NZmY1qaGhgba2Ntrb26tdSq/V1dXR0NDQq3UcCmZmOzBkyBAmTpxY7TIqxsNHZmaWKzwUJA2S9Iikn6X5iZKWSGqVdKukoal9jzTfmvonFF2bmZm9XSWOFD4LrCiZ/xpwbbpTuoPs6aukz47Ufm1azszMKqjQUJDUAHwcuDHNCziR7NWeAM28dRPctDRP6p+s/ngNmJlZP1b0kcI3yZ60+maaHw1siIg30nwb2fueSZ8vAKT+jWl5MzOrkMJCQdJpwNqIWNrH250tqUVSS3+8RMzM7J2syCOF44Cpkp4FbiEbNvoWMCK94xmgAViZplcC4yF/B/Q+wLquG42IuRHRFBFN9fX1BZZvZlZ7CguFiPhyRDRExATgLGBxRJwD3AuckRabCdyRphemeVL/4uhvtxCamfVz1bhP4VLgYkmtZOcM5qX2ecDo1H4x2XuhzcysgipyR3NE3Afcl6afAY7qZpktwF9Voh4zM+ue72g2M7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHKFhYKkOkkPSvqdpCckXZXaJ0paIqlV0q2Shqb2PdJ8a+qfUFRtZmbWvSKPFF4DToyIDwOHASdLOhr4GnBtRBwAdACz0vKzgI7Ufm1azszMKqiwUIjMpjQ7JP0EcCJwW2pvBqan6WlpntQ/WZKKqs/MzLZX6DkFSYMkLQPWAouAPwAbIuKNtEgbMC5NjwNeAEj9G4HRRdZnZmZvV2goRMS2iDgMaACOAj64u9uUNFtSi6SW9vb23d2cmZmVqMjVRxGxAbgXOAYYIWlw6moAVqbplcB4gNS/D7Cum23NjYimiGiqr68vunQzs5pS5NVH9ZJGpOk9gSnACrJwOCMtNhO4I00vTPOk/sUREUXVZ2Zm2xu880V22b5As6RBZOGzICJ+Jmk5cIukvwMeAeal5ecBN0lqBdYDZxVYm5mZdaOwUIiIR4HDu2l/huz8Qtf2LcBfFVWPmZntnO9oNjOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8sVFgqSxku6V9JySU9I+mxqHyVpkaSn0+fI1C5J10lqlfSopCOKqs3MzLpX5JHCG8AXIuIg4GjgIkkHAXOAeyKiEbgnzQOcAjSmn9nADQXWZmZm3SgsFCJiVUQ8nKZfBlYA44BpQHNarBmYnqanAfMj8wAwQtK+RdVnZmbbq8g5BUkTgMOBJcDYiFiVulYDY9P0OOCFktXaUlvXbc2W1CKppb29vbiizcxqUOGhIGlv4MfA5yLipdK+iAggerO9iJgbEU0R0VRfX9+HlZqZWaGhIGkIWSD8ICJ+kprXdA4Lpc+1qX0lML5k9YbUZmZmFVLk1UcC5gErIuIbJV0LgZlpeiZwR0n7jHQV0tHAxpJhJjMzq4DBBW77OOA84DFJy1LbV4BrgAWSZgHPAWemvl8ApwKtwCvA+QXWZmZm3SgsFCLiN4B66J7czfIBXFRUPWZmtnO+o9nMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyxX5PoV3rl/OgdWPVbsKM7Nd954/hVOu6fPN+kjBzMxytXmkUEC6mpkNBD5SMDOzXGGhIOnfJK2V9HhJ2yhJiyQ9nT5HpnZJuk5Sq6RHJR1RVF1mZtazIo8Uvg+c3KVtDnBPRDQC96R5gFOAxvQzG7ihwLrMzKwHhYVCRPwnsL5L8zSgOU03A9NL2udH5gFghKR9i6rNzMy6V+lzCmMjYlWaXg2MTdPjgBdKlmtLbduRNFtSi6SW9vb24io1M6tBVTvRHBEBxC6sNzcimiKiqb6+voDKzMxqV6VDYU3nsFD6XJvaVwLjS5ZrSG1mZlZBlQ6FhcDMND0TuKOkfUa6CuloYGPJMJOZmVWIslGcAjYs3QycAIwB1gBXALcDC4D9geeAMyNivSQB/0x2tdIrwPkR0VLGPtrTdnbFGODFXVy3v/J3rg3+zrVhd77zeyOi2/H3wkLhnU5SS0Q0VbuOSvJ3rg3+zrWhqO/sO5rNzCznUDAzs1wth8LcahdQBf7OtcHfuTYU8p1r9pyCmZltr5aPFMzMrAuHgpmZ5WoyFCSdLOmp9KjuOTtfo3/r7jHmA52k8ZLulbRc0hOSPlvtmoomqU7Sg5J+l77zVdWuqRIkDZL0iKSfVbuWSpD0rKTHJC2TtNP7uXq9/Vo7pyBpEPB7YArZg/ceAj4REcurWliBJP05sInsSbSHVLueSkiPUdk3Ih6WNBxYCkwf4P+fBQyLiE2ShgC/AT6bnjw8YEm6GGgC3hURp1W7nqJJehZoiohCbtarxSOFo4DWiHgmIl4HbiF7dPeA1cNjzAe0iFgVEQ+n6ZeBFfTw5N2BIj16flOaHZJ+BvRffZIagI8DN1a7loGiFkOh7Md028AgaQJwOLCkyqUULg2lLCN72OSiiBjo3/mbwCXAm1Wuo5ICuFvSUkmz+3rjtRgKVkMk7Q38GPhcRLxU7XqKFhHbIuIwsicNHyVpwA4XSjoNWBsRS6tdS4UdHxFHkL2x8qI0PNxnajEU/JjuGpHG1X8M/CAiflLteiopIjYA97L9K3EHkuOAqWmM/RbgREn/Xt2SihcRK9PnWuCnZEPifaYWQ+EhoFHSRElDgbPIHt1tA0g66ToPWBER36h2PZUgqV7SiDS9J9nFFE9WtagCRcSXI6IhIiaQ/TteHBHnVrmsQkkali6cQNIw4GNAn15VWHOhEBFvAH8L/Irs5OOCiHiiulUVKz3G/LfAgZLaJM2qdk0VcBxwHtlfj8vSz6nVLqpg+wL3SnqU7I+fRRFRE5dp1pCxwG8k/Q54EPh5RNzVlzuouUtSzcysZzV3pGBmZj1zKJiZWc6hYGZmOYeCmZnlHApmZpZzKFhNkTRW0g8lPZMeE/BbSf+9SrWcIOnYkvlPSZpRjVrMOg2udgFmlZJuaLsdaI6Is1Pbe4GpBe5zcLo3pjsnkD299v8BRMR3iqrDrFy+T8FqhqTJwOUR8ZFu+gYB15D9ot4DuD4ivivpBOBK4EXgELJHcJ8bESHpSOAbwN6p/5MRsUrSfcAy4HjgZrJHtV8GDAXWAecAewIPANuAduAzwGRgU0R8XdJhwHeAvYA/ABdEREfa9hLgL4ARwKyI+HXf/Bcy8/CR1ZaDgYd76JsFbIyIScAk4K8lTUx9hwOfAw4C3gccl56r9G3gjIg4Evg34O9Ltjc0Ipoi4p/I3mtwdEQcTvaMnksi4lmyX/rXRsRh3fxinw9cGhGHAo8BV5T0DY6Io1JNV2DWhzx8ZDVL0vVkf82/DjwHHCrpjNS9D9CY+h6MiLa0zjJgArCB7MhhUTYqxSBgVcnmby2ZbgBuTS/+GQr8107q2gcYERH3p6Zm4Ecli3Q+3G9pqsWszzgUrJY8Afxl50xEXCRpDNACPA98JiJ+VbpCGj56raRpG9m/GwFPRMQxPexrc8n0t4FvRMTCkuGo3dFZT2ctZn3Gw0dWSxYDdZI+XdK2V/r8FfDpNCyEpA+kp1D25CmgXtIxafkhkg7uYdl9eOvx7DNL2l8GhnddOCI2Ah2S/iw1nQfc33U5syL4rwyrGenk8HTgWkmXkJ3g3QxcSjY8MwF4OF2l1A5M38G2Xk9DTdel4Z7BZG8B6+6Ju1cCP5LUQRZMnecq7gRukzSN7ERzqZnAdyTtBTwDnN/Lr2u2S3z1kZmZ5Tx8ZGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpb7/2LoL9nTqN4KAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ag.plot_fitness()\n",
    "ag.plot_individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ag(\"ag_larger_architecture\",  ag, 2, 1500, 100, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ele demorou 29 min e 46,2 s para otimizar. Curiosamente, todos os modelos pareceram extremamente iguais. Acreditamos que isso se deve a alta taxa de dropout. Tentamos então otimizar apenas a regularização L2 e o droput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_hist = {}\n",
    "\n",
    "def optimize_larger_reg(individual:np.ndarray):\n",
    "    individual = np.round(individual, 5)\n",
    "    name = str(individual[0])+\"_\"+str(individual[1])+\"_\"+str(individual[2])+\"_\"+str(individual[3])\n",
    "    arch_name = \"larger_ag_reg_\"+name\n",
    "    model_name = arch_name+\"_week\"\n",
    "\n",
    "    if name in fitness_hist:\n",
    "        return fitness_hist[name]\n",
    "\n",
    "\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(853, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(individual[0]))(input)\n",
    "    x = tf.keras.layers.Dropout(individual[2])(x)\n",
    "\n",
    "    x = keras.layers.Dense(121, activation=\"relu\",  kernel_regularizer=keras.regularizers.l2(individual[1]))(x)\n",
    "    x = tf.keras.layers.Dropout(individual[3])(x)\n",
    "    \n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    manager.register_model(model, model_name,  arch_name)\n",
    "    manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=100, batch_size=int(BATCH_SIZE/7))\n",
    "\n",
    "    fitness = np.mean(manager._hist[model_name].history[\"val_mean_squared_error\"][-10:])\n",
    "\n",
    "    fitness_hist[name] = fitness\n",
    "\n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AG(10, 1, 0.01, cross_over=one_point, dtype=np.float64)\n",
    "ag.optimize(optimize_larger_reg, 4, 1, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ag(\"ag_larger_reg\",  ag, 4, 1, 0, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa nova execução demorou 32 min e 5,6s. Tivemos mudanças mais significativas nas métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos então que, até o momento, estávamos utilizando como valor para o fitness a média da loss de validação. Porém, o AG está implementado de forma a maximizar o fitness, o que implica em maximizar a loss. Todos os testes até então tentaram des-otimizar a arquitetura.\n",
    "\n",
    "Alteramos o fitness para ser o recíproco da média da loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_hist = {}\n",
    "\n",
    "def optimize_larger2(individual:np.ndarray):\n",
    "    ind = individual.astype(int)\n",
    "    name = str(ind[0])+\"_\"+str(ind[1])\n",
    "    arch_name = \"larger_ag_\"+name\n",
    "    model_name = arch_name+\"_week\"\n",
    "\n",
    "    if name in fitness_hist:\n",
    "        return fitness_hist[name]\n",
    "\n",
    "\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(ind[0], activation=\"relu\")(input)\n",
    "    x = keras.layers.Dense(ind[1], activation=\"relu\")(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    manager.register_model(model, model_name,  arch_name)\n",
    "    manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=60, batch_size=int(BATCH_SIZE/7))\n",
    "\n",
    "    fitness = np.mean(manager._hist[model_name].history[\"val_mean_squared_error\"][-10:])\n",
    "    fitness = 1.0/fitness\n",
    "\n",
    "    fitness_hist[name] = fitness\n",
    "\n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AG(10, 1, 10, cross_over=one_point)\n",
    "ag.optimize(optimize_larger2, 2, 1500, 100, 6)\n",
    "log_ag(\"ag_larger_architecture_minimize\",  ag, 2, 1500, 100, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tivemos \"melhorias\" ao alterar a regularização, tentamos então otimizar tanto ela quanto a arquitetura. Também executamos esse experimento com gerações maiores (20 indivíduos, o dobro), e por mais gerações (12, o dobro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_hist = {}\n",
    "\n",
    "def optimize_both(individual:np.ndarray):\n",
    "    individual = np.round(individual, decimals=5)\n",
    "    individual = np.clip(individual, 0.0, 1.0)\n",
    "\n",
    "    units = individual[:2]\n",
    "    reg = individual[2:]\n",
    "\n",
    "    reg = np.clip(reg, 0.0, 0.99999)\n",
    "\n",
    "    units *= 1900\n",
    "    units += 100\n",
    "    units = units.astype(int)\n",
    "\n",
    "    name = \"\"\n",
    "    for i in range(2):\n",
    "        name += str(units[i])+\"_\"\n",
    "    for i in range(4):\n",
    "        name += str(reg[i])+\"_\"\n",
    "    \n",
    "    arch_name = \"larger_ag_both_\"+name\n",
    "    model_name = arch_name+\"week\"\n",
    "\n",
    "    if name in fitness_hist:\n",
    "        return fitness_hist[name]\n",
    "\n",
    "\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(units[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l2(reg[0]))(input)\n",
    "    x = tf.keras.layers.Dropout(reg[2])(x)\n",
    "    \n",
    "    x = keras.layers.Dense(units[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l2(reg[1]))(x)\n",
    "    x = tf.keras.layers.Dropout(reg[3])(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    manager.register_model(model, model_name,  arch_name)\n",
    "    manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=60, batch_size=int(BATCH_SIZE/7), group=\"ag_optimize_both2\", verbose=0)\n",
    "\n",
    "    fitness = np.mean(manager._hist[model_name].history[\"val_mean_squared_error\"][-10:])\n",
    "    fitness = 1.0/fitness\n",
    "\n",
    "    fitness_hist[name] = fitness\n",
    "\n",
    "    return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AG(20, 1, 0.1, cross_over=one_point, dtype=np.float64)\n",
    "ag.optimize(optimize_both, 6, 1, 0, 12)\n",
    "log_ag(\"ag_larger_both2\",  ag, 6, 1, 0, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ag(\"ag_larger_both2\",  ag, 6, 1, 0, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tivemos que parar a otimização no meio do processo, por risco de danificar o computador durante uma tempestade, serializamos e salvamos o AG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"ag_backup\", 'wb')\n",
    "pickle.dump(ag, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"ag_backup\", 'rb')\n",
    "ag = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função para continuar o processo de evolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_optimize(self, fitness_function, n_generation):\n",
    "    stopped_generation = self.current_generation\n",
    "\n",
    "    for i in range(stopped_generation, n_generation):\n",
    "        print(\"Iniciando geração\", i)\n",
    "        for j in range(self.population_size):\n",
    "            self.fitness_scores[j] = fitness_function(self.population[j])\n",
    "\n",
    "        self.population = self.new_population()\n",
    "\n",
    "        self.mutation_range_hist[self.current_generation] = self.mutation_range\n",
    "        self.mutation_rate_hist[self.current_generation] = self.mutation_rate\n",
    "\n",
    "        if i > 0:\n",
    "            if(abs(self.fitness_best_hist[i] - self.fitness_best_hist[i-1]) < 1E-4):\n",
    "                self.stopped_count += 1\n",
    "            else:\n",
    "                self.stopped_count = 0\n",
    "        \n",
    "        self.current_generation += 1\n",
    "\n",
    "        if self.stopped_count > self.mutation_patience:\n",
    "            # Para -> Refina -> Para -> Explora -> Reset\n",
    "            if (self.exploration_count > self.exploration_patience and \n",
    "                self.refinement_count > self.refinement_patience):\n",
    "                #Reset\n",
    "                    self.mutation_rate = self.initial_mutation_rate\n",
    "                    self.mutation_range = self.initial_mutation_range\n",
    "\n",
    "                    self.refinement_count = 0\n",
    "                    self.exploration_count = 0\n",
    "                    \n",
    "            elif self.refinement_count > self.refinement_patience:\n",
    "                if self.exploration_count == 0:\n",
    "                    # 1ª iteração de exploração\n",
    "                    self.mutation_rate = self.initial_mutation_rate\n",
    "                    self.mutation_range = self.initial_mutation_range\n",
    "                \n",
    "                #Exploração \n",
    "                if self.dynamic_rate:\n",
    "                    self.mutation_rate *= 2.0\n",
    "                if self.dynamic_range:\n",
    "                    self.mutation_range *= 2.0\n",
    "\n",
    "                self.exploration_count += 1\n",
    "                self.generation_type[self.current_generation] = 1\n",
    "            \n",
    "            else:\n",
    "                #Refinamento\n",
    "                if self.dynamic_rate:\n",
    "                    self.mutation_rate /= 2.0\n",
    "                if self.dynamic_range:\n",
    "                    self.mutation_range /= 2.0\n",
    "                \n",
    "                self.refinement_count += 1\n",
    "\n",
    "                self.generation_type[self.current_generation] = -1\n",
    "\n",
    "            self.stopped_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "ag.continue_optimize = types.MethodType(continue_optimize, ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E terminamos a otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag.continue_optimize(optimize_both, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ag(\"ag_larger_both3\",  ag, 6, 1, 0, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "O AG conseguiu gerar resultados interessantes, porém não chegou ao melhor resultado que tínhamos conseguido alterando manualmente os parâmetros. Talvez utilizar outros parâmetros para o AG, ou treinar por mais gerações, poderia resolver o problema.\n",
    "\n",
    "Como não tínhamos tempo para isso, e não é o objetivo desse trabalho gerar o modelo mais otimizado de todos, decidimos parar a hiperotimização com os resultados que já tivemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino dos melhores\n",
    "\n",
    "Por fim, treinamos os melhores algoritmos por mais epochs, com parada antecipada. Os modelos não treinaram muito mais que já haviam sido treinados anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ag_best\n",
    "\n",
    "Melhor modelo selecionado pelo AG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08171292, 0.83180579, 0.33090176, 0.00938583, 0.51035982,\n",
       "       0.63681597])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag.individual_best_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidades: 255 1680\n",
      "Regularização L2: 0.3309 0.00939\n",
      "Dropout: 0.51036 0.63682\n"
     ]
    }
   ],
   "source": [
    "def print_best(individual:np.ndarray):\n",
    "    individual = np.round(individual, decimals=5)\n",
    "    individual = np.clip(individual, 0.0, 1.0)\n",
    "\n",
    "    units = individual[:2]\n",
    "    reg = individual[2:]\n",
    "\n",
    "    reg = np.clip(reg, 0.0, 0.99999)\n",
    "\n",
    "    units *= 1900\n",
    "    units += 100\n",
    "    units = units.astype(int)\n",
    "\n",
    "    print(\"Unidades:\",units[0], units[1])\n",
    "    print(\"Regularização L2:\", reg[0], reg[1])\n",
    "    print(\"Dropout:\", reg[2], reg[3])\n",
    "\n",
    "print_best(ag.individual_best_hist[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ag_best():\n",
    "    input = keras.Input(shape=(n_features), name=\"input\")\n",
    "    \n",
    "    x = keras.layers.Dense(255, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.3309))(input)\n",
    "    x = tf.keras.layers.Dropout(0.51036)(x)\n",
    "    \n",
    "    x = keras.layers.Dense(1680, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.00939))(x)\n",
    "    x = tf.keras.layers.Dropout(0.63682)(x)\n",
    "\n",
    "    out = keras.layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=[input], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/breath/BReATH/runs/233999x1\" target=\"_blank\">sandy-capybara-505</a></strong> to <a href=\"https://wandb.ai/breath/BReATH\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 3s 33ms/step - loss: 13.8653 - mean_absolute_error: 0.3459 - mean_squared_error: 5.4861 - val_loss: 21.1583 - val_mean_absolute_error: 0.4982 - val_mean_squared_error: 15.0168\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 9.7514 - mean_absolute_error: 0.2927 - mean_squared_error: 4.9348 - val_loss: 20.0301 - val_mean_absolute_error: 0.5187 - val_mean_squared_error: 16.4139\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 7.8064 - mean_absolute_error: 0.2745 - mean_squared_error: 4.8766 - val_loss: 16.4926 - val_mean_absolute_error: 0.4623 - val_mean_squared_error: 14.2075\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 6.7065 - mean_absolute_error: 0.2732 - mean_squared_error: 4.8158 - val_loss: 17.8614 - val_mean_absolute_error: 0.5267 - val_mean_squared_error: 16.3386\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 6.0625 - mean_absolute_error: 0.2703 - mean_squared_error: 4.7664 - val_loss: 15.9549 - val_mean_absolute_error: 0.4897 - val_mean_squared_error: 14.8767\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 5.7065 - mean_absolute_error: 0.2713 - mean_squared_error: 4.7658 - val_loss: 16.1855 - val_mean_absolute_error: 0.5011 - val_mean_squared_error: 15.3716\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 5.5187 - mean_absolute_error: 0.2654 - mean_squared_error: 4.7812 - val_loss: 15.2057 - val_mean_absolute_error: 0.4773 - val_mean_squared_error: 14.5592\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.3091 - mean_absolute_error: 0.2654 - mean_squared_error: 4.7275 - val_loss: 15.9688 - val_mean_absolute_error: 0.5062 - val_mean_squared_error: 15.4311\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.2727 - mean_absolute_error: 0.2707 - mean_squared_error: 4.7573 - val_loss: 15.3260 - val_mean_absolute_error: 0.4885 - val_mean_squared_error: 14.8348\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 5.1591 - mean_absolute_error: 0.2682 - mean_squared_error: 4.6914 - val_loss: 14.1550 - val_mean_absolute_error: 0.4752 - val_mean_squared_error: 13.7181\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.1583 - mean_absolute_error: 0.2775 - mean_squared_error: 4.7268 - val_loss: 15.2859 - val_mean_absolute_error: 0.4948 - val_mean_squared_error: 14.8662\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.1076 - mean_absolute_error: 0.2705 - mean_squared_error: 4.6915 - val_loss: 14.1441 - val_mean_absolute_error: 0.4600 - val_mean_squared_error: 13.7413\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.0909 - mean_absolute_error: 0.2801 - mean_squared_error: 4.7092 - val_loss: 14.8508 - val_mean_absolute_error: 0.4818 - val_mean_squared_error: 14.4672\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.0507 - mean_absolute_error: 0.2761 - mean_squared_error: 4.6745 - val_loss: 14.1084 - val_mean_absolute_error: 0.4684 - val_mean_squared_error: 13.7317\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 5.0122 - mean_absolute_error: 0.2803 - mean_squared_error: 4.6391 - val_loss: 14.2588 - val_mean_absolute_error: 0.4751 - val_mean_squared_error: 13.8890\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.9882 - mean_absolute_error: 0.2793 - mean_squared_error: 4.6206 - val_loss: 15.0596 - val_mean_absolute_error: 0.4896 - val_mean_squared_error: 14.6921\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 5.0066 - mean_absolute_error: 0.2790 - mean_squared_error: 4.6401 - val_loss: 14.6628 - val_mean_absolute_error: 0.4736 - val_mean_squared_error: 14.2899\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.9793 - mean_absolute_error: 0.2787 - mean_squared_error: 4.6162 - val_loss: 15.0108 - val_mean_absolute_error: 0.4845 - val_mean_squared_error: 14.6454\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.9508 - mean_absolute_error: 0.2779 - mean_squared_error: 4.5897 - val_loss: 14.7365 - val_mean_absolute_error: 0.4851 - val_mean_squared_error: 14.3781\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.9899 - mean_absolute_error: 0.2777 - mean_squared_error: 4.6225 - val_loss: 14.9415 - val_mean_absolute_error: 0.4922 - val_mean_squared_error: 14.5873\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.9027 - mean_absolute_error: 0.2776 - mean_squared_error: 4.5438 - val_loss: 14.4485 - val_mean_absolute_error: 0.4692 - val_mean_squared_error: 14.0914\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.9294 - mean_absolute_error: 0.2771 - mean_squared_error: 4.5757 - val_loss: 14.6336 - val_mean_absolute_error: 0.4805 - val_mean_squared_error: 14.2818\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 4.9261 - mean_absolute_error: 0.2786 - mean_squared_error: 4.5697 - val_loss: 15.3389 - val_mean_absolute_error: 0.4947 - val_mean_squared_error: 14.9834\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.9038 - mean_absolute_error: 0.2774 - mean_squared_error: 4.5510 - val_loss: 14.6160 - val_mean_absolute_error: 0.4830 - val_mean_squared_error: 14.2657\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8869 - mean_absolute_error: 0.2783 - mean_squared_error: 4.5248 - val_loss: 14.0886 - val_mean_absolute_error: 0.4634 - val_mean_squared_error: 13.7152\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.9124 - mean_absolute_error: 0.2774 - mean_squared_error: 4.5466 - val_loss: 14.0564 - val_mean_absolute_error: 0.4798 - val_mean_squared_error: 13.7030\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.8988 - mean_absolute_error: 0.2769 - mean_squared_error: 4.5435 - val_loss: 14.1772 - val_mean_absolute_error: 0.4690 - val_mean_squared_error: 13.8222\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8361 - mean_absolute_error: 0.2786 - mean_squared_error: 4.4773 - val_loss: 14.5432 - val_mean_absolute_error: 0.4753 - val_mean_squared_error: 14.1781\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8633 - mean_absolute_error: 0.2785 - mean_squared_error: 4.5141 - val_loss: 14.5039 - val_mean_absolute_error: 0.4924 - val_mean_squared_error: 14.1557\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8431 - mean_absolute_error: 0.2752 - mean_squared_error: 4.4719 - val_loss: 13.4316 - val_mean_absolute_error: 0.4527 - val_mean_squared_error: 13.0473\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8444 - mean_absolute_error: 0.2780 - mean_squared_error: 4.4676 - val_loss: 13.4536 - val_mean_absolute_error: 0.4625 - val_mean_squared_error: 13.0828\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8331 - mean_absolute_error: 0.2780 - mean_squared_error: 4.4641 - val_loss: 15.2466 - val_mean_absolute_error: 0.5134 - val_mean_squared_error: 14.8705\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.8251 - mean_absolute_error: 0.2810 - mean_squared_error: 4.4541 - val_loss: 13.1350 - val_mean_absolute_error: 0.4548 - val_mean_squared_error: 12.7751\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.8055 - mean_absolute_error: 0.2764 - mean_squared_error: 4.4372 - val_loss: 13.3811 - val_mean_absolute_error: 0.4491 - val_mean_squared_error: 13.0027\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8155 - mean_absolute_error: 0.2791 - mean_squared_error: 4.4461 - val_loss: 14.6058 - val_mean_absolute_error: 0.4790 - val_mean_squared_error: 14.2375\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.8259 - mean_absolute_error: 0.2798 - mean_squared_error: 4.4498 - val_loss: 12.6577 - val_mean_absolute_error: 0.4328 - val_mean_squared_error: 12.2907\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.7962 - mean_absolute_error: 0.2794 - mean_squared_error: 4.4253 - val_loss: 12.2335 - val_mean_absolute_error: 0.4209 - val_mean_squared_error: 11.8689\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.7855 - mean_absolute_error: 0.2780 - mean_squared_error: 4.4183 - val_loss: 12.5133 - val_mean_absolute_error: 0.4305 - val_mean_squared_error: 12.1405\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.7636 - mean_absolute_error: 0.2761 - mean_squared_error: 4.3832 - val_loss: 12.7462 - val_mean_absolute_error: 0.4403 - val_mean_squared_error: 12.3626\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.7171 - mean_absolute_error: 0.2780 - mean_squared_error: 4.3384 - val_loss: 12.8178 - val_mean_absolute_error: 0.4400 - val_mean_squared_error: 12.4342\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.7352 - mean_absolute_error: 0.2791 - mean_squared_error: 4.3549 - val_loss: 12.3344 - val_mean_absolute_error: 0.4194 - val_mean_squared_error: 11.9515\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.7858 - mean_absolute_error: 0.2738 - mean_squared_error: 4.4055 - val_loss: 12.0916 - val_mean_absolute_error: 0.4419 - val_mean_squared_error: 11.7087\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.7136 - mean_absolute_error: 0.2746 - mean_squared_error: 4.3282 - val_loss: 12.6497 - val_mean_absolute_error: 0.4560 - val_mean_squared_error: 12.2664\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.6837 - mean_absolute_error: 0.2768 - mean_squared_error: 4.2989 - val_loss: 13.4489 - val_mean_absolute_error: 0.4837 - val_mean_squared_error: 13.0526\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.7126 - mean_absolute_error: 0.2772 - mean_squared_error: 4.3083 - val_loss: 11.7140 - val_mean_absolute_error: 0.4117 - val_mean_squared_error: 11.3189\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.6828 - mean_absolute_error: 0.2769 - mean_squared_error: 4.2999 - val_loss: 11.8364 - val_mean_absolute_error: 0.4053 - val_mean_squared_error: 11.4430\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.7371 - mean_absolute_error: 0.2757 - mean_squared_error: 4.3391 - val_loss: 12.6864 - val_mean_absolute_error: 0.4625 - val_mean_squared_error: 12.2952\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.7226 - mean_absolute_error: 0.2730 - mean_squared_error: 4.3259 - val_loss: 11.4873 - val_mean_absolute_error: 0.3950 - val_mean_squared_error: 11.0911\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.6986 - mean_absolute_error: 0.2756 - mean_squared_error: 4.2984 - val_loss: 11.3968 - val_mean_absolute_error: 0.4053 - val_mean_squared_error: 10.9892\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.6962 - mean_absolute_error: 0.2779 - mean_squared_error: 4.2970 - val_loss: 11.3748 - val_mean_absolute_error: 0.3870 - val_mean_squared_error: 10.9872\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6486 - mean_absolute_error: 0.2733 - mean_squared_error: 4.2548 - val_loss: 11.2311 - val_mean_absolute_error: 0.4064 - val_mean_squared_error: 10.8303\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6693 - mean_absolute_error: 0.2772 - mean_squared_error: 4.2701 - val_loss: 11.5159 - val_mean_absolute_error: 0.3799 - val_mean_squared_error: 11.1149\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.7348 - mean_absolute_error: 0.2760 - mean_squared_error: 4.3264 - val_loss: 11.2866 - val_mean_absolute_error: 0.3782 - val_mean_squared_error: 10.9018\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.6405 - mean_absolute_error: 0.2741 - mean_squared_error: 4.2427 - val_loss: 11.0784 - val_mean_absolute_error: 0.3926 - val_mean_squared_error: 10.6860\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6023 - mean_absolute_error: 0.2742 - mean_squared_error: 4.2140 - val_loss: 11.1160 - val_mean_absolute_error: 0.3879 - val_mean_squared_error: 10.7256\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6017 - mean_absolute_error: 0.2754 - mean_squared_error: 4.1978 - val_loss: 10.8268 - val_mean_absolute_error: 0.3831 - val_mean_squared_error: 10.4317\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6249 - mean_absolute_error: 0.2739 - mean_squared_error: 4.2209 - val_loss: 10.9720 - val_mean_absolute_error: 0.3846 - val_mean_squared_error: 10.5729\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.5785 - mean_absolute_error: 0.2760 - mean_squared_error: 4.1781 - val_loss: 10.8599 - val_mean_absolute_error: 0.3884 - val_mean_squared_error: 10.4759\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.5659 - mean_absolute_error: 0.2734 - mean_squared_error: 4.1671 - val_loss: 10.7524 - val_mean_absolute_error: 0.3799 - val_mean_squared_error: 10.3524\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.5965 - mean_absolute_error: 0.2768 - mean_squared_error: 4.2120 - val_loss: 11.5010 - val_mean_absolute_error: 0.3911 - val_mean_squared_error: 11.1078\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.5116 - mean_absolute_error: 0.2755 - mean_squared_error: 4.1149 - val_loss: 11.3839 - val_mean_absolute_error: 0.3664 - val_mean_squared_error: 10.9811\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.6217 - mean_absolute_error: 0.2710 - mean_squared_error: 4.2071 - val_loss: 11.1084 - val_mean_absolute_error: 0.3650 - val_mean_squared_error: 10.7090\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.5168 - mean_absolute_error: 0.2740 - mean_squared_error: 4.1219 - val_loss: 11.8075 - val_mean_absolute_error: 0.3809 - val_mean_squared_error: 11.4102\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.4869 - mean_absolute_error: 0.2706 - mean_squared_error: 4.0906 - val_loss: 11.8587 - val_mean_absolute_error: 0.4180 - val_mean_squared_error: 11.4458\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.5382 - mean_absolute_error: 0.2743 - mean_squared_error: 4.1275 - val_loss: 11.0235 - val_mean_absolute_error: 0.3684 - val_mean_squared_error: 10.6178\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.4909 - mean_absolute_error: 0.2719 - mean_squared_error: 4.0900 - val_loss: 11.5511 - val_mean_absolute_error: 0.3751 - val_mean_squared_error: 11.1547\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.4747 - mean_absolute_error: 0.2726 - mean_squared_error: 4.0724 - val_loss: 11.6613 - val_mean_absolute_error: 0.3809 - val_mean_squared_error: 11.2561\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.4766 - mean_absolute_error: 0.2691 - mean_squared_error: 4.0607 - val_loss: 12.2580 - val_mean_absolute_error: 0.3989 - val_mean_squared_error: 11.8450\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.4130 - mean_absolute_error: 0.2723 - mean_squared_error: 4.0073 - val_loss: 12.2356 - val_mean_absolute_error: 0.3902 - val_mean_squared_error: 11.8214\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.4494 - mean_absolute_error: 0.2715 - mean_squared_error: 4.0516 - val_loss: 12.1143 - val_mean_absolute_error: 0.3765 - val_mean_squared_error: 11.7187\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.4585 - mean_absolute_error: 0.2697 - mean_squared_error: 4.0621 - val_loss: 11.5244 - val_mean_absolute_error: 0.3754 - val_mean_squared_error: 11.1383\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.4269 - mean_absolute_error: 0.2695 - mean_squared_error: 4.0274 - val_loss: 12.6081 - val_mean_absolute_error: 0.3900 - val_mean_squared_error: 12.2088\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.4265 - mean_absolute_error: 0.2702 - mean_squared_error: 4.0390 - val_loss: 11.7506 - val_mean_absolute_error: 0.3743 - val_mean_squared_error: 11.3567\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.3896 - mean_absolute_error: 0.2680 - mean_squared_error: 3.9808 - val_loss: 12.3645 - val_mean_absolute_error: 0.3911 - val_mean_squared_error: 11.9542\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.4686 - mean_absolute_error: 0.2684 - mean_squared_error: 4.0637 - val_loss: 11.8411 - val_mean_absolute_error: 0.4019 - val_mean_squared_error: 11.4523\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3908 - mean_absolute_error: 0.2661 - mean_squared_error: 3.9911 - val_loss: 11.7868 - val_mean_absolute_error: 0.3887 - val_mean_squared_error: 11.3817\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3999 - mean_absolute_error: 0.2682 - mean_squared_error: 4.0023 - val_loss: 12.4469 - val_mean_absolute_error: 0.4131 - val_mean_squared_error: 12.0567\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.3298 - mean_absolute_error: 0.2674 - mean_squared_error: 3.9337 - val_loss: 12.0390 - val_mean_absolute_error: 0.3933 - val_mean_squared_error: 11.6450\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3671 - mean_absolute_error: 0.2685 - mean_squared_error: 3.9656 - val_loss: 12.1919 - val_mean_absolute_error: 0.4088 - val_mean_squared_error: 11.7943\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3440 - mean_absolute_error: 0.2705 - mean_squared_error: 3.9515 - val_loss: 11.8754 - val_mean_absolute_error: 0.3882 - val_mean_squared_error: 11.4888\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3834 - mean_absolute_error: 0.2697 - mean_squared_error: 3.9788 - val_loss: 12.4824 - val_mean_absolute_error: 0.3968 - val_mean_squared_error: 12.0791\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3206 - mean_absolute_error: 0.2681 - mean_squared_error: 3.9263 - val_loss: 12.4961 - val_mean_absolute_error: 0.3984 - val_mean_squared_error: 12.1108\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3346 - mean_absolute_error: 0.2681 - mean_squared_error: 3.9422 - val_loss: 12.8114 - val_mean_absolute_error: 0.4040 - val_mean_squared_error: 12.4062\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3641 - mean_absolute_error: 0.2696 - mean_squared_error: 3.9680 - val_loss: 12.3093 - val_mean_absolute_error: 0.3946 - val_mean_squared_error: 11.9161\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3439 - mean_absolute_error: 0.2658 - mean_squared_error: 3.9481 - val_loss: 12.3426 - val_mean_absolute_error: 0.3978 - val_mean_squared_error: 11.9546\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3440 - mean_absolute_error: 0.2701 - mean_squared_error: 3.9711 - val_loss: 12.4897 - val_mean_absolute_error: 0.4017 - val_mean_squared_error: 12.1154\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3339 - mean_absolute_error: 0.2639 - mean_squared_error: 3.9432 - val_loss: 12.9296 - val_mean_absolute_error: 0.4257 - val_mean_squared_error: 12.5298\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2914 - mean_absolute_error: 0.2670 - mean_squared_error: 3.9089 - val_loss: 12.2364 - val_mean_absolute_error: 0.4003 - val_mean_squared_error: 11.8568\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.3386 - mean_absolute_error: 0.2665 - mean_squared_error: 3.9316 - val_loss: 12.9008 - val_mean_absolute_error: 0.4004 - val_mean_squared_error: 12.4921\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2781 - mean_absolute_error: 0.2650 - mean_squared_error: 3.8844 - val_loss: 13.0845 - val_mean_absolute_error: 0.4120 - val_mean_squared_error: 12.6934\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2596 - mean_absolute_error: 0.2656 - mean_squared_error: 3.8736 - val_loss: 13.0288 - val_mean_absolute_error: 0.4085 - val_mean_squared_error: 12.6415\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2653 - mean_absolute_error: 0.2640 - mean_squared_error: 3.8738 - val_loss: 12.9624 - val_mean_absolute_error: 0.4025 - val_mean_squared_error: 12.5658\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2889 - mean_absolute_error: 0.2648 - mean_squared_error: 3.9009 - val_loss: 13.0929 - val_mean_absolute_error: 0.4249 - val_mean_squared_error: 12.7139\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2712 - mean_absolute_error: 0.2654 - mean_squared_error: 3.8868 - val_loss: 12.3502 - val_mean_absolute_error: 0.4032 - val_mean_squared_error: 11.9702\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.2633 - mean_absolute_error: 0.2668 - mean_squared_error: 3.8744 - val_loss: 13.0294 - val_mean_absolute_error: 0.4070 - val_mean_squared_error: 12.6435\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2154 - mean_absolute_error: 0.2623 - mean_squared_error: 3.8247 - val_loss: 12.9693 - val_mean_absolute_error: 0.4081 - val_mean_squared_error: 12.5799\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2804 - mean_absolute_error: 0.2624 - mean_squared_error: 3.8844 - val_loss: 13.1042 - val_mean_absolute_error: 0.4234 - val_mean_squared_error: 12.7111\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2497 - mean_absolute_error: 0.2626 - mean_squared_error: 3.8559 - val_loss: 12.8946 - val_mean_absolute_error: 0.4150 - val_mean_squared_error: 12.5045\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.2426 - mean_absolute_error: 0.2640 - mean_squared_error: 3.8593 - val_loss: 13.2525 - val_mean_absolute_error: 0.4219 - val_mean_squared_error: 12.8753\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.1884 - mean_absolute_error: 0.2664 - mean_squared_error: 3.8142 - val_loss: 13.1850 - val_mean_absolute_error: 0.4154 - val_mean_squared_error: 12.8022\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 4.2568 - mean_absolute_error: 0.2619 - mean_squared_error: 3.8725 - val_loss: 13.2399 - val_mean_absolute_error: 0.4190 - val_mean_squared_error: 12.8566\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.2014 - mean_absolute_error: 0.2620 - mean_squared_error: 3.8269 - val_loss: 12.7635 - val_mean_absolute_error: 0.4203 - val_mean_squared_error: 12.3953\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.2021 - mean_absolute_error: 0.2630 - mean_squared_error: 3.8269 - val_loss: 13.3148 - val_mean_absolute_error: 0.4300 - val_mean_squared_error: 12.9316\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.1607 - mean_absolute_error: 0.2603 - mean_squared_error: 3.7791 - val_loss: 13.1004 - val_mean_absolute_error: 0.4253 - val_mean_squared_error: 12.7201\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.2109 - mean_absolute_error: 0.2660 - mean_squared_error: 3.8199 - val_loss: 13.5372 - val_mean_absolute_error: 0.4173 - val_mean_squared_error: 13.1517\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 4.2002 - mean_absolute_error: 0.2626 - mean_squared_error: 3.8156 - val_loss: 13.0916 - val_mean_absolute_error: 0.4195 - val_mean_squared_error: 12.7186\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.1864 - mean_absolute_error: 0.2636 - mean_squared_error: 3.8152 - val_loss: 13.1614 - val_mean_absolute_error: 0.4100 - val_mean_squared_error: 12.7822\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.1817 - mean_absolute_error: 0.2619 - mean_squared_error: 3.7972 - val_loss: 13.3607 - val_mean_absolute_error: 0.4204 - val_mean_squared_error: 12.9887\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 4.1561 - mean_absolute_error: 0.2611 - mean_squared_error: 3.7859 - val_loss: 13.3505 - val_mean_absolute_error: 0.4180 - val_mean_squared_error: 12.9767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\plotly\\matplotlylib\\renderer.py:612: UserWarning:\n",
      "\n",
      "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6388... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476b8e6a89cf40d487c0f3079cff37c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 5.03MB of 5.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_absolute_error</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_squared_error</td><td>█▅▅▅▅▅▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▄▃▃▄▄▄▃▄▃▃▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃</td></tr><tr><td>val_mean_absolute_error</td><td>█▆█▇▆▆▇██▆▇▆▅▄▅▅▃▂▂▂▂▂▁▄▂▂▁▃▂▃▂▃▃▃▃▄▄▄▄▄</td></tr><tr><td>val_mean_squared_error</td><td>█▆█▇▆▆▆▇▇▆▆▅▅▃▄▃▂▂▂▂▁▁▂▃▂▃▂▃▃▃▃▃▄▄▄▄▄▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>58</td></tr><tr><td>best_val_mean_squared_error</td><td>10.35238</td></tr><tr><td>epoch</td><td>108</td></tr><tr><td>loss</td><td>4.15608</td></tr><tr><td>mean_absolute_error</td><td>0.26107</td></tr><tr><td>mean_squared_error</td><td>3.78593</td></tr><tr><td>val_loss</td><td>13.35047</td></tr><tr><td>val_mean_absolute_error</td><td>0.41795</td></tr><tr><td>val_mean_squared_error</td><td>12.97665</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">sandy-capybara-505</strong>: <a href=\"https://wandb.ai/breath/BReATH/runs/233999x1\" target=\"_blank\">https://wandb.ai/breath/BReATH/runs/233999x1</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211213_151455-233999x1\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_ag_best()\n",
    "manager.register_model(model, \"ag_best\", \"ag_best\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=1000, batch_size=int(BATCH_SIZE/7), patience=50)\n",
    "manager.save(\"ag_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### larger_reg3\n",
    "\n",
    "Melhor de todos  (possuia a melhor MSE de validação na última epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_larger_reg3()\n",
    "manager.register_model(model, \"larger_reg3_longer\", \"larger_reg3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=1000, batch_size=int(BATCH_SIZE/7), patience=50)\n",
    "manager.save(\"larger_reg3_longer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  lstm3_longer\n",
    "\n",
    "Melhor LSTM (possuia a melhor MSE de validação na última epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm3()\n",
    "manager.register_model(model, \"lstm3_longer\", \"lstm3\")\n",
    "manager.compile_fit_save(optimizer=keras.optimizers.Adam(), epochs=1000, batch_size=int(BATCH_SIZE/7), patience=50)\n",
    "manager.save(\"lstm3_longer\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
